{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp daft_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willsa/git/bedmap-dev/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "import daft\n",
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TimmEmbedder:\n",
    "    \"\"\"\n",
    "    embed an image with any timm model that supports this\n",
    "\n",
    "    Reference: https://huggingface.co/docs/timm/main/en/feature_extraction#pooled\n",
    "    \"\"\"\n",
    "    model_name: str\n",
    "    device: torch.device = field(init=False)\n",
    "    dtype: torch.dtype = field(init=False)\n",
    "    _model: Callable = field(init=False)\n",
    "    _transforms: Callable = field(init=False)\n",
    "\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # initialize model and transforms\n",
    "        self._model = timm.create_model(self.model_name, pretrained=True, num_classes=0)\n",
    "        cfg = self._model.pretrained_cfg\n",
    "        self._transform = timm.data.create_transform(**timm.data.resolve_data_config(cfg))\n",
    "\n",
    "        # set device and dtype\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dtype = torch.bfloat16 if self.device.type == \"cuda\" and torch.cuda.is_bf16_supported() else (\n",
    "            torch.float16 if self.device.type == \"cuda\" else torch.float32\n",
    "        )\n",
    "        print(f\"Inference device: {self.device} with dtype: {self.dtype}\")\n",
    "\n",
    "        # optimize model for inference\n",
    "        self._model = self._model.eval().to(device=self.device, dtype=self.dtype)\n",
    "        self._model = torch.jit.optimize_for_inference(torch.jit.script(self._model))\n",
    "\n",
    "\n",
    "    def __call__(self, image: torch.Tensor | Image.Image) -> np.array:\n",
    "            \"\"\"transform image, run inference, extract embedding as 1D array\"\"\"\n",
    "            image = self._transform(image).to(self.device, self.dtype).unsqueeze(0)\n",
    "            emb = self._model(image)\n",
    "            return emb.detach().cpu().float().numpy().squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference device: cpu with dtype: torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.17605317,  0.0147213 , -0.05652565, ..., -0.1414647 ,\n",
       "        0.16466515,  0.0450598 ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "# it's a one-stop shop\n",
    "e = TimmEmbedder(\"mobilenetv3_large_100\")\n",
    "e(torch.rand((3,256,256)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@daft.udf(return_dtype=daft.DataType.tensor(daft.DataType.float32()))\n",
    "class EmbedImages:\n",
    "    \"\"\"run timm embedder on an image column\"\"\"\n",
    "    def __init__(self, model_name: str):\n",
    "        self.model_name = model_name\n",
    "        self.embedder = TimmEmbedder(self.model_name)\n",
    "\n",
    "    def __call__(self, images_col):\n",
    "        images = images_col.to_pylist()\n",
    "        print(f\"First type: {type(images[0])}\")\n",
    "        print(f\"First shape: {images[0].shape}\")\n",
    "        ## TODO: Modify to work on an array instead of a list\n",
    "        ## Example: https://colab.research.google.com/github/Eventual-Inc/Daft/blob/main/tutorials/mnist.ipynb\n",
    "        # return [self.embedder(torch.tensor(image)) for image in images]\n",
    "        return [np.random.random((512,)) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willsa/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/context.py:168: UserWarning: Daft is configured to use the new NativeRunner by default as of v0.4.0. If you are encountering any regressions, please switch back to the legacy PyRunner via `daft.context.set_runner_py()` or by setting the env variable `DAFT_RUNNER=py`. We appreciate you filing issues and helping make the NativeRunner better: https://github.com/Eventual-Inc/Daft/issues\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "im_cols = daft.from_glob_path(\"../../../atlas-compare/data/orig_filt/*.png\"\n",
    "                              ).with_column_renamed(\"path\", \"path_full_img\")\n",
    "\n",
    "im_cols = im_cols.sample(0.01)\n",
    "\n",
    "im_cols = im_cols.with_column(\"image\", daft.col(\"path_full_img\"\n",
    "                                 ).url.download().image.decode(\n",
    "                                     mode=\"RGB\", on_error=\"null\"))\n",
    "\n",
    "MODEL_NAME = \"mobilenetv3_large_100\"\n",
    "EmbedImagesWithModel = EmbedImages.with_init_args(MODEL_NAME)\n",
    "\n",
    "im_cols = im_cols.with_column(\"embed\", EmbedImagesWithModel(daft.col(\"image\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference device: cpu with dtype: torch.float32\n",
      "First type: <class 'numpy.ndarray'>\n",
      "First shape: (157, 132, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "thread 'Compute-Thread-15' panicked at src/daft-core/src/array/ops/cast.rs:2192:18:\n",
      "not implemented: List casting not implemented for dtype: Tensor(Float32)\n",
      "note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n",
      "--- PyO3 is resuming a panic after fetching a PanicException from Python. ---\n",
      "Python stack trace below:\n"
     ]
    },
    {
     "ename": "PanicException",
     "evalue": "not implemented: List casting not implemented for dtype: Tensor(Float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPanicException\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/udf.py:169\u001b[0m, in \u001b[0;36mrun_udf\u001b[0;34m(func, bound_args, evaluated_expressions, py_return_dtype, batch_size)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Series\u001b[38;5;241m.\u001b[39mfrom_pylist(result_list, name\u001b[38;5;241m=\u001b[39mname, pyobj\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39m_series\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pylist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpyobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_series\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmodule_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    171\u001b[0m     result_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(results)\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/series.py:157\u001b[0m, in \u001b[0;36mSeries.cast\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcast\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: DataType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Series\u001b[38;5;241m.\u001b[39m_from_pyseries(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_series\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mPanicException\u001b[0m: not implemented: List casting not implemented for dtype: Tensor(Float32)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error when running pipeline node Project\n"
     ]
    },
    {
     "ename": "DaftCoreException",
     "evalue": "DaftError::External task 14177 panicked with message \"not implemented: List casting not implemented for dtype: Tensor(Float32)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDaftCoreException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mim_cols\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/api_annotations.py:26\u001b[0m, in \u001b[0;36mDataframePublicAPI.<locals>._wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m type_check_function(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     25\u001b[0m timed_method \u001b[38;5;241m=\u001b[39m time_df_method(func)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtimed_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/analytics.py:199\u001b[0m, in \u001b[0;36mtime_df_method.<locals>.tracked_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    201\u001b[0m     _ANALYTICS_CLIENT\u001b[38;5;241m.\u001b[39mtrack_df_method_call(\n\u001b[1;32m    202\u001b[0m         method_name\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, duration_seconds\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start, error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    203\u001b[0m     )\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/dataframe/dataframe.py:2891\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   2878\u001b[0m \u001b[38;5;129m@DataframePublicAPI\u001b[39m\n\u001b[1;32m   2879\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2880\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes enough of the DataFrame in order to display the first ``n`` rows.\u001b[39;00m\n\u001b[1;32m   2881\u001b[0m \n\u001b[1;32m   2882\u001b[0m \u001b[38;5;124;03m    If IPython is installed, this will use IPython's `display` utility to pretty-print in a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2889\u001b[0m \u001b[38;5;124;03m        n: number of rows to show. Defaults to 8.\u001b[39;00m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2891\u001b[0m     dataframe_display \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_show_display\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2892\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2893\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/dataframe/dataframe.py:2848\u001b[0m, in \u001b[0;36mDataFrame._construct_show_display\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   2846\u001b[0m tables \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2847\u001b[0m seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 2848\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iter_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_buffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtables\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseen\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/runners/native_runner.py:90\u001b[0m, in \u001b[0;36mNativeRunner.run_iter_tables\u001b[0;34m(self, builder, results_buffer_size)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_iter_tables\u001b[39m(\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m, builder: LogicalPlanBuilder, results_buffer_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     89\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[MicroPartition]:\n\u001b[0;32m---> 90\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_buffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresults_buffer_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/runners/native_runner.py:85\u001b[0m, in \u001b[0;36mNativeRunner.run_iter\u001b[0;34m(self, builder, results_buffer_size)\u001b[0m\n\u001b[1;32m     78\u001b[0m executor \u001b[38;5;241m=\u001b[39m NativeExecutor()\n\u001b[1;32m     79\u001b[0m results_gen \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m     80\u001b[0m     builder,\n\u001b[1;32m     81\u001b[0m     {k: v\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_part_set_cache\u001b[38;5;241m.\u001b[39mget_all_partition_sets()\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[1;32m     82\u001b[0m     daft_execution_config,\n\u001b[1;32m     83\u001b[0m     results_buffer_size,\n\u001b[1;32m     84\u001b[0m )\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m results_gen\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/execution/native_executor.py:39\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdaft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartitioning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LocalMaterializedResult\n\u001b[1;32m     34\u001b[0m psets_mp \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     35\u001b[0m     part_id: [part\u001b[38;5;241m.\u001b[39mmicropartition()\u001b[38;5;241m.\u001b[39m_micropartition \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m parts] \u001b[38;5;28;01mfor\u001b[39;00m part_id, parts \u001b[38;5;129;01min\u001b[39;00m psets\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     36\u001b[0m }\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m     LocalMaterializedResult(MicroPartition\u001b[38;5;241m.\u001b[39m_from_pymicropartition(part))\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor\u001b[38;5;241m.\u001b[39mrun(builder\u001b[38;5;241m.\u001b[39m_builder, psets_mp, daft_execution_config, results_buffer_size)\n\u001b[1;32m     40\u001b[0m )\n",
      "\u001b[0;31mDaftCoreException\u001b[0m: DaftError::External task 14177 panicked with message \"not implemented: List casting not implemented for dtype: Tensor(Float32)\""
     ]
    }
   ],
   "source": [
    "im_cols.show(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
