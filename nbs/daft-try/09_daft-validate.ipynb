{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "from collections.abc import Callable\n",
    "\n",
    "import daft\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "GLOB_PATH: str = \"../../tests/test-data/butterflies_baseline/data/originals/*.jpg\"\n",
    "MIN_BYTES: int = 300\n",
    "MIN_ASPECT: float = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willsa/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/context.py:168: UserWarning: Daft is configured to use the new NativeRunner by default as of v0.4.0. If you are encountering any regressions, please switch back to the legacy PyRunner via `daft.context.set_runner_py()` or by setting the env variable `DAFT_RUNNER=py`. We appreciate you filing issues and helping make the NativeRunner better: https://github.com/Eventual-Inc/Daft/issues\n",
      "  warnings.warn(\n",
      "/home/willsa/git/bedmap-dev/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      d\r"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "\n",
    "df_img = daft.from_glob_path(GLOB_PATH).with_column_renamed(\"path\", \"img_path\")\n",
    "\n",
    "# create image name column\n",
    "df_img = df_img.with_column(\"img_name\", df_img[\"img_path\"].str.split(\"/\").list.get(-1).cast(str))\n",
    "\n",
    "# get the images since we'll need to use them several times\n",
    "df_img = df_img.with_column(\n",
    "    \"img\", daft.col(\"img_path\").url.download(on_error=\"null\").image.decode(on_error=\"null\", mode=\"RGB\")\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "\n",
    "def split_on_condition(df: daft.DataFrame, condition: Callable[[daft.DataFrame], daft.DataFrame]):\n",
    "    \"\"\"Splits a DataFrame into accepted and dropped rows based on a filtering condition.\n",
    "\n",
    "    Args:\n",
    "        df (daft.DataFrame): The input DataFrame.\n",
    "        condition (Callable[[daft.DataFrame], daft.DataFrame]): A function that filters the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[daft.DataFrame, daft.DataFrame]: (accepted_df, dropped_df)\n",
    "    \"\"\"\n",
    "    filtered_df = condition(df)\n",
    "    if filtered_df.count_rows() < df.count_rows():\n",
    "        dropped_df = filtered_df.except_distinct(df)\n",
    "        return filtered_df, dropped_df\n",
    "    else:\n",
    "        return df, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "# Define filtering functions\n",
    "def size_nontrivial(df: daft.DataFrame) -> daft.DataFrame:\n",
    "    \"\"\"Keeps images that are at least MIN_BYTES in size on disk.\"\"\"\n",
    "    return df.filter(df[\"size\"] > MIN_BYTES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "\n",
    "@daft.udf(return_dtype=daft.DataType.bool())\n",
    "def array_not_oblong(arrs: daft.Series, max_oblongness: float = 4.0) -> bool:\n",
    "    \"\"\"is an array oblong\"\"\"\n",
    "    arrs = arrs.to_pylist()\n",
    "    shapes = np.array([a.shape[:2] for a in arrs])  # Extract h, w as an array\n",
    "    max_aspects = np.max(shapes / shapes[:, ::-1], axis=1)  # Compute max(h/w, w/h)\n",
    "    return max_aspects < max_oblongness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "\n",
    "def img_not_oblong(df: daft.DataFrame) -> daft.DataFrame:\n",
    "    \"\"\"Keeps images with an aspect ratio between 1:4 and 4:1 using Daft's `image_decode`.\"\"\"\n",
    "    # checkable = decoded.with_column(\"is_not_oblong\", df[\"img\"].apply(array_not_oblong, daft.DataType.bool()))\n",
    "    checkable = df.with_column(\"is_not_oblong\", array_not_oblong(df_img[\"img\"]))\n",
    "    checked = checkable.filter(checkable[\"is_not_oblong\"]).exclude(\"is_not_oblong\")  # Drop transient column\n",
    "    return checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "\n",
    "def img_name_distinct(df: daft.DataFrame, name_col: str = \"img_name\") -> daft.DataFrame:\n",
    "    \"\"\"Keeps images with unique filenames.\"\"\"\n",
    "    aggs = [daft.col(c).any_value() for c in set(df_img.column_names) - {name_col}]\n",
    "    return df.groupby(name_col).agg(*aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "# Define pipeline of conditions\n",
    "pipeline: list[Callable[[daft.DataFrame], daft.DataFrame]] = [size_nontrivial, img_not_oblong, img_name_distinct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking size_nontrivial\n",
      "Checking img_not_oblong\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Checking img_name_distinct                          d\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "\n",
    "# Process the pipeline\n",
    "for check in pipeline:\n",
    "    print(f\"Checking {check.__qualname__}\")\n",
    "    df_img, dropped = split_on_condition(df_img, check)\n",
    "\n",
    "    if dropped:\n",
    "        print(f\"{dropped.count_rows()} images failed check {check.__name__} and will be dropped.\")\n",
    "        print(dropped.head(1))  # Print first dropped row as an example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
