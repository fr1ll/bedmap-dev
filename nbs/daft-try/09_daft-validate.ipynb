{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "from collections.abc import Callable\n",
    "\n",
    "import daft\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOB_PATH: str = \"../../tests/test-data/butterflies_baseline/data/originals/*.jpg\"\n",
    "MIN_BYTES: int = 300\n",
    "MIN_ASPECT: float = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willsa/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/context.py:168: UserWarning: Daft is configured to use the new NativeRunner by default as of v0.4.0. If you are encountering any regressions, please switch back to the legacy PyRunner via `daft.context.set_runner_py()` or by setting the env variable `DAFT_RUNNER=py`. We appreciate you filing issues and helping make the NativeRunner better: https://github.com/Eventual-Inc/Daft/issues\n",
      "  warnings.warn(\n",
      "/home/willsa/git/bedmap-dev/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      d\r"
     ]
    }
   ],
   "source": [
    "df_img = daft.from_glob_path(GLOB_PATH).with_column_renamed(\"path\", \"img_path\")\n",
    "\n",
    "# create image name column\n",
    "df_img = df_img.with_column(\"img_name\",\n",
    "                   df_img[\"img_path\"].str.split(\"/\").list.get(\n",
    "                       -1).cast(str))\n",
    "\n",
    "# get the images since we'll need to use them several times\n",
    "df_img = df_img.with_column(\"img\", daft.col(\"img_path\"\n",
    "                                   ).url.download(on_error=\"null\"\n",
    "                                                  ).image.decode(on_error=\"null\",\n",
    "                                                                 mode=\"RGB\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_img.count_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_on_condition(df: daft.DataFrame, condition: Callable[[daft.DataFrame], daft.DataFrame]):\n",
    "    \"\"\"Splits a DataFrame into accepted and dropped rows based on a filtering condition.\n",
    "\n",
    "    Args:\n",
    "        df (daft.DataFrame): The input DataFrame.\n",
    "        condition (Callable[[daft.DataFrame], daft.DataFrame]): A function that filters the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[daft.DataFrame, daft.DataFrame]: (accepted_df, dropped_df)\n",
    "    \"\"\"\n",
    "    filtered_df = condition(df)\n",
    "    if filtered_df.count_rows() < df.count_rows():\n",
    "        dropped_df = filtered_df.except_distinct(df)\n",
    "        return filtered_df, dropped_df\n",
    "    else:\n",
    "        return df, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filtering functions\n",
    "def size_nontrivial(df: daft.DataFrame) -> daft.DataFrame:\n",
    "    \"\"\"Keeps images that are at least MIN_BYTES in size on disk.\"\"\"\n",
    "    return df.filter(df[\"size\"] > MIN_BYTES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@daft.udf(return_dtype=daft.DataType.bool())\n",
    "def array_not_oblong(arrs: daft.Series, max_oblongness: float=4.0) -> bool:\n",
    "    \"\"\"is an array oblong\"\"\"\n",
    "    arrs = arrs.to_pylist()\n",
    "    shapes = np.array([a.shape[:2] for a in arrs])  # Extract h, w as an array\n",
    "    max_aspects = np.max(shapes / shapes[:, ::-1], axis=1)  # Compute max(h/w, w/h)\n",
    "    return max_aspects < max_oblongness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_not_oblong(df: daft.DataFrame) -> daft.DataFrame:\n",
    "    \"\"\"Keeps images with an aspect ratio between 1:4 and 4:1 using Daft's `image_decode`.\"\"\"\n",
    "    # checkable = decoded.with_column(\"is_not_oblong\", df[\"img\"].apply(array_not_oblong, daft.DataType.bool()))\n",
    "    checkable = df.with_column(\"is_not_oblong\", array_not_oblong(df_img[\"img\"]))\n",
    "    checked = checkable.filter(checkable[\"is_not_oblong\"]\n",
    "                             ).exclude(\"is_not_oblong\") # Drop transient column\n",
    "    return checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_name_distinct(df: daft.DataFrame, name_col: str=\"img_name\") -> daft.DataFrame:\n",
    "    \"\"\"Keeps images with unique filenames.\"\"\"\n",
    "    aggs = [daft.col(c).any_value() for c in set(df_img.column_names) - {name_col}]\n",
    "    return df.groupby(name_col).agg(*aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define pipeline of conditions\n",
    "pipeline: list[Callable[[daft.DataFrame], daft.DataFrame]] = [\n",
    "    size_nontrivial,\n",
    "    img_not_oblong,\n",
    "    img_name_distinct\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'condition' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Process the pipeline\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m check \u001b[38;5;129;01min\u001b[39;00m pipeline:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChecking \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcondition\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     df_img, dropped \u001b[38;5;241m=\u001b[39m split_on_condition(df_img, check)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dropped:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'condition' is not defined"
     ]
    }
   ],
   "source": [
    "# Process the pipeline\n",
    "for check in pipeline:\n",
    "    print(f\"Checking {check.__qualname__}\")\n",
    "    df_img, dropped = split_on_condition(df_img, check)\n",
    "\n",
    "    if dropped:\n",
    "        print(f\"{dropped.count_rows()} images failed check {check.__name__} and will be dropped.\")\n",
    "        print(dropped.head(1))  # Print first dropped row as an example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
