{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from datasets import load_dataset\n",
    "import gc\n",
    "import torch.profiler as profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constants\n",
    "MAX_IMAGES = 50\n",
    "BATCH_SIZE = 12\n",
    "MODEL_NAME = \"vit_base_patch14_reg4_dinov2.lvd142m\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp_path = Path(\"./tmp-test-images\")\n",
    "shutil.rmtree(tmp_path, ignore_errors=True)\n",
    "tmp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset_name = \"kvriza8/microscopy_images\"\n",
    "dataset = load_dataset(dataset_name, split=\"train\", streaming=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:04, 10.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i, example in enumerate(tqdm(iter(dataset))):  # Stream images to avoid full load\n",
    "    if i >= MAX_IMAGES:\n",
    "        break\n",
    "    image = example[\"image\"]\n",
    "    image.save(tmp_path / f\"{i}.png\")\n",
    "\n",
    "del dataset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform):\n",
    "        self.img_paths = list(Path(img_dir).glob(\"*.png\"))\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        with Image.open(img_path).convert(\"RGB\") as img:\n",
    "            img_tensor = self.transform(img)\n",
    "        return img_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class TimmEmbedder:\n",
    "    model_name: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.device = torch.device(\"cpu\")  # Ensure CPU inference\n",
    "        self.model = timm.create_model(self.model_name, pretrained=True, num_classes=0)\n",
    "        self.model = self.model.to(self.device).eval()\n",
    "        cfg = self.model.pretrained_cfg\n",
    "        self.transform = timm.data.create_transform(**timm.data.resolve_data_config(cfg))\n",
    "\n",
    "    def prepare(self, image):\n",
    "        return self.transform(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def embed(self, img_tensor):\n",
    "        with torch.no_grad():\n",
    "            return self.model(img_tensor).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedder = TimmEmbedder(MODEL_NAME)\n",
    "dataset = ImageDataset(tmp_path, embedder.transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "embeddings = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [01:12<00:00, 14.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::addmm        59.93%       42.810s        65.36%       46.691s     194.545ms      21.23 Gb      21.23 Gb           240  \n",
      "                                             aten::gelu         3.69%        2.635s         3.69%        2.635s      43.917ms       9.43 Gb       9.43 Gb            60  \n",
      "                                            aten::empty         0.01%       7.142ms         0.01%       7.142ms      11.595us       5.46 Gb       5.46 Gb           616  \n",
      "                                              aten::add         1.73%        1.239s         1.73%        1.239s       9.913ms       4.91 Gb       4.91 Gb           125  \n",
      "                                              aten::mul         1.37%     980.940ms         1.37%     980.940ms       8.175ms       4.72 Gb       4.72 Gb           120  \n",
      "                                    aten::empty_strided         0.01%       6.339ms         0.01%       6.339ms      17.610us       2.81 Gb       2.81 Gb           360  \n",
      "                                              aten::cat         0.40%     283.495ms         0.40%     284.751ms      18.983ms     508.34 Mb     508.34 Mb            15  \n",
      "                                              aten::div         0.08%      59.910ms         0.08%      60.653ms       1.213ms     153.54 Mb     153.54 Mb            50  \n",
      "                                              aten::any         0.00%       2.203ms         0.00%       2.718ms      27.179us         100 b         100 b           100  \n",
      "                                          aten::random_         0.00%      64.020us         0.00%      64.020us      64.020us           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 71.436s\n",
      "\n",
      "Embedding shape: (50, 768)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with profiler.profile(activities=[profiler.ProfilerActivity.CPU],\n",
    "                      record_shapes=True, profile_memory=True) as prof:\n",
    "    for i, batch in enumerate(tqdm(dataloader, desc=\"Processing batches\")):\n",
    "        batch = torch.cat([embedder.prepare(img) for img in batch], dim=0)\n",
    "        batch_embeddings = embedder.embed(batch)\n",
    "        embeddings.append(batch_embeddings)\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            gc.collect()\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))\n",
    "\n",
    "embeddings = np.vstack(embeddings)\n",
    "print(\"Embedding shape:\", embeddings.shape)\n",
    "\n",
    "shutil.rmtree(tmp_path)\n",
    "\n",
    "# sum(e.nbytes for e in embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph written to /tmp/objgraph-mooah0r8.dot (17 nodes)\n",
      "Spawning graph viewer (xdot)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/xdot/ui/elements.py:178: UserWarning: Font family 'Times-Roman' is not available, using 'Cantarell 11'\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import objgraph\n",
    "objgraph.show_backrefs([embedder], max_depth=3)  # Visualize lingering references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
