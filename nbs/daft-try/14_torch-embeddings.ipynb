{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from datasets import load_dataset\n",
    "import gc\n",
    "\n",
    "# Constants\n",
    "MAX_IMAGES = 2000\n",
    "BATCH_SIZE = 12\n",
    "MODEL_NAME = \"vit_base_patch14_reg4_dinov2.lvd142m\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp_path = Path(\"./tmp-test-images\")\n",
    "shutil.rmtree(tmp_path, ignore_errors=True)\n",
    "tmp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset_name = \"kvriza8/microscopy_images\"\n",
    "dataset = load_dataset(dataset_name, split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, example in enumerate(tqdm(iter(dataset))):  # Stream images to avoid full load\n",
    "    if i >= MAX_IMAGES:\n",
    "        break\n",
    "    image = example[\"image\"]\n",
    "    image.save(tmp_path / f\"{i}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform):\n",
    "        self.img_paths = list(Path(img_dir).glob(\"*.png\"))\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        with Image.open(img_path).convert(\"RGB\") as img:\n",
    "            img_tensor = self.transform(img)\n",
    "        return img_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class TimmEmbedder:\n",
    "    model_name: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = timm.create_model(self.model_name, pretrained=True, num_classes=0)\n",
    "        self.model = self.model.to(self.device).eval()\n",
    "        cfg = self.model.pretrained_cfg\n",
    "        self.transform = timm.data.create_transform(**timm.data.resolve_data_config(cfg))\n",
    "\n",
    "    def prepare(self, image):\n",
    "        return self.transform(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def embed(self, img_tensor):\n",
    "        with torch.no_grad():\n",
    "            return self.model(img_tensor).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedder = TimmEmbedder(MODEL_NAME)\n",
    "dataset = ImageDataset(tmp_path, embedder.transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = []\n",
    "\n",
    "for i, batch in enumerate(tqdm(dataloader, desc=\"Processing batches\")):\n",
    "    batch = torch.cat([embedder.prepare(img) for img in batch], dim=0)\n",
    "    batch_embeddings = embedder.embed(batch)\n",
    "    embeddings.append(batch_embeddings)\n",
    "    # if i%25 == 0:\n",
    "    #     print(torch.cuda.memory_summary())\n",
    "    if i%5 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print(f\"Size of embeddings: {sum(e.nbytes for e in embeddings)}\")\n",
    "\n",
    "\n",
    "embeddings = np.vstack(embeddings)\n",
    "print(\"Embedding shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shutil.rmtree(tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(e.nbytes for e in embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
