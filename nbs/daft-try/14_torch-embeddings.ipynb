{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from datasets import load_dataset\n",
    "import gc\n",
    "\n",
    "# Constants\n",
    "MAX_IMAGES = 2000\n",
    "BATCH_SIZE = 12\n",
    "MODEL_NAME = \"vit_base_patch14_reg4_dinov2.lvd142m\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp_path = Path(\"./tmp-test-images\")\n",
    "shutil.rmtree(tmp_path, ignore_errors=True)\n",
    "tmp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset_name = \"kvriza8/microscopy_images\"\n",
    "dataset = load_dataset(dataset_name, split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:39, 51.13it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, example in enumerate(tqdm(iter(dataset))):  # Stream images to avoid full load\n",
    "    if i >= MAX_IMAGES:\n",
    "        break\n",
    "    image = example[\"image\"]\n",
    "    image.save(tmp_path / f\"{i}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform):\n",
    "        self.img_paths = list(Path(img_dir).glob(\"*.png\"))\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        with Image.open(img_path).convert(\"RGB\") as img:\n",
    "            img_tensor = self.transform(img)\n",
    "        return img_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class TimmEmbedder:\n",
    "    model_name: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = timm.create_model(self.model_name, pretrained=True, num_classes=0)\n",
    "        self.model = self.model.to(self.device).eval()\n",
    "        cfg = self.model.pretrained_cfg\n",
    "        self.transform = timm.data.create_transform(**timm.data.resolve_data_config(cfg))\n",
    "\n",
    "    def prepare(self, image):\n",
    "        return self.transform(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def embed(self, img_tensor):\n",
    "        with torch.no_grad():\n",
    "            return self.model(img_tensor).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "embedder = TimmEmbedder(MODEL_NAME)\n",
    "dataset = ImageDataset(tmp_path, embedder.transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   1%|          | 1/167 [00:15<43:12, 15.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 36864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   4%|▎         | 6/167 [01:34<42:22, 15.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 221184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   7%|▋         | 11/167 [02:56<42:23, 16.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 405504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  10%|▉         | 16/167 [04:19<42:08, 16.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 589824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  13%|█▎        | 21/167 [05:43<40:37, 16.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 774144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  16%|█▌        | 26/167 [07:07<39:34, 16.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 958464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  19%|█▊        | 31/167 [08:32<38:21, 16.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 1142784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  22%|██▏       | 36/167 [09:56<37:09, 17.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 1327104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  25%|██▍       | 41/167 [11:20<34:54, 16.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 1511424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  28%|██▊       | 46/167 [12:43<33:29, 16.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 1695744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  31%|███       | 51/167 [14:06<32:10, 16.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 1880064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  34%|███▎      | 56/167 [15:30<31:13, 16.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 2064384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  37%|███▋      | 61/167 [16:52<29:02, 16.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 2248704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  40%|███▉      | 66/167 [18:13<27:22, 16.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 2433024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  43%|████▎     | 71/167 [19:34<25:53, 16.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 2617344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  46%|████▌     | 76/167 [20:55<24:37, 16.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 2801664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  49%|████▊     | 81/167 [22:17<23:28, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 2985984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  51%|█████▏    | 86/167 [23:39<22:05, 16.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 3170304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  54%|█████▍    | 91/167 [25:01<20:54, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 3354624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  57%|█████▋    | 96/167 [26:23<19:29, 16.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of embeddings: 3538944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  60%|█████▉    | 100/167 [27:29<18:29, 16.55s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings = []\n",
    "\n",
    "for i, batch in enumerate(tqdm(dataloader, desc=\"Processing batches\")):\n",
    "    batch = torch.cat([embedder.prepare(img) for img in batch], dim=0)\n",
    "    batch_embeddings = embedder.embed(batch)\n",
    "    embeddings.append(batch_embeddings)\n",
    "    # if i%25 == 0:\n",
    "    #     print(torch.cuda.memory_summary())\n",
    "    if i%5 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print(f\"Size of embeddings: {sum(e.nbytes for e in embeddings)}\")\n",
    "\n",
    "\n",
    "embeddings = np.vstack(embeddings)\n",
    "print(\"Embedding shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shutil.rmtree(tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(e.nbytes for e in embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
