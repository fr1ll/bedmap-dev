{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp daft_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import daft\n",
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from einops import rearrange\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from datasets import load_dataset\n",
    "\n",
    "import shutil\n",
    "import memray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "daft.set_execution_config(enable_native_executor=True,\n",
    "                          default_morsel_size=1\n",
    "                          )\n",
    "\n",
    "MAX_IMAGES = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:38, 51.71it/s] \n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "tmp_path = Path(\"./tmp-test-images\")\n",
    "shutil.rmtree(tmp_path, ignore_errors=True)\n",
    "tmp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset_name = \"kvriza8/microscopy_images\"\n",
    "\n",
    "dataset = load_dataset(dataset_name, split=\"train\", streaming=True)\n",
    "\n",
    "for i, example in enumerate(tqdm(iter(dataset))):  # Use iterator to avoid full load\n",
    "    if i >= MAX_IMAGES:\n",
    "        break\n",
    "    image = example[\"image\"]\n",
    "    image.save(tmp_path / f\"{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@dataclass\n",
    "class TimmEmbedder:\n",
    "    \"\"\"\n",
    "    embed an image with any timm model that supports this\n",
    "\n",
    "    Reference: https://huggingface.co/docs/timm/main/en/feature_extraction#pooled\n",
    "    \"\"\"\n",
    "    model_name: str\n",
    "    device: torch.device = field(init=False)\n",
    "    dtype: torch.dtype = field(init=False)\n",
    "    _model: Callable = field(init=False)\n",
    "    _transforms: Callable = field(init=False)\n",
    "    _amp_autocast: Callable = field(default=None, init=False, repr=False)\n",
    "    _instance: \"TimmEmbedder\" = field(default=None, init=False, repr=False)\n",
    "\n",
    "    def __new__(cls, model_name):\n",
    "        if not hasattr(cls, \"_instance\") or cls._instance is None:\n",
    "            cls._instance = super().__new__(cls)\n",
    "        return cls._instance\n",
    "\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if hasattr(self, \"_model\"):  # Avoid re-initialization\n",
    "            return\n",
    "        # initialize model and transforms\n",
    "        self._model = timm.create_model(self.model_name, pretrained=True, num_classes=0)\n",
    "        cfg = self._model.pretrained_cfg\n",
    "        self._transform = timm.data.create_transform(**timm.data.resolve_data_config(cfg))\n",
    "\n",
    "        # set device, dtype, and autocast function\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.dtype = torch.bfloat16 if self.device.type == \"cuda\" and torch.cuda.is_bf16_supported() else (\n",
    "            torch.float16 if self.device.type == \"cuda\" else torch.float32\n",
    "        )\n",
    "        print(f\"Inference device: {self.device} with dtype: {self.dtype}\")\n",
    "\n",
    "        # optimize model for inference\n",
    "        self._model = self._model.eval().to(device=self.device, dtype=self.dtype)\n",
    "        # self._model = torch.jit.optimize_for_inference(torch.jit.script(self._model))\n",
    "        self._model = torch.compile(self._model)\n",
    "\n",
    "\n",
    "    def __call__(self, image: torch.Tensor | Image.Image) -> np.array:\n",
    "            \"\"\"transform image, run inference, extract embedding as 1D array\"\"\"\n",
    "            image = self._transform(image).to(self.device, self.dtype).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                emb = self._model(image)\n",
    "            result = emb.detach().cpu().float().numpy().squeeze()\n",
    "            del image, emb\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# it's a one-stop shop\n",
    "# e = TimmEmbedder(\"mobilenetv3_large_100\")\n",
    "# e(torch.rand((3,256,256)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@daft.udf(return_dtype=daft.DataType.list(daft.DataType.float32()),\n",
    "          memory_bytes=int(6e9)) # 6 Gb resource request\n",
    "class EmbedImages:\n",
    "    \"\"\"run timm embedder on an image column\"\"\"\n",
    "    def __init__(self, model_name: str):\n",
    "        self.model_name = model_name\n",
    "        self.embedder = TimmEmbedder(self.model_name)\n",
    "\n",
    "    def __call__(self, images_col):\n",
    "        images = [rearrange(im, \"h w c -> c h w\") for im in images_col.to_pylist()]\n",
    "        ## Note: expect images are different sizes\n",
    "        ## could maybe speed up by doing the resize transform separately,\n",
    "        ## then doing batch inference\n",
    "        ## Example: https://colab.research.google.com/github/Eventual-Inc/Daft/blob/main/tutorials/mnist.ipynb\n",
    "        return [self.embedder(\n",
    "            torch.tensor(im, dtype=self.embedder.dtype)) for im in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willsa/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/context.py:168: UserWarning: Daft is configured to use the new NativeRunner by default as of v0.4.0. If you are encountering any regressions, please switch back to the legacy PyRunner via `daft.context.set_runner_py()` or by setting the env variable `DAFT_RUNNER=py`. We appreciate you filing issues and helping make the NativeRunner better: https://github.com/Eventual-Inc/Daft/issues\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "glob = tmp_path.as_posix() +\"/*.png\"\n",
    "images_df = daft.from_glob_path(glob).with_column_renamed(\"path\", \"path_full_img\")\n",
    "\n",
    "images_df = images_df.with_column(\"image\", daft.col(\"path_full_img\"\n",
    "                                 ).url.download().image.decode(\n",
    "                                     mode=\"RGB\", on_error=\"null\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference time for some embedding models on CPU on my laptop\n",
    "\n",
    "model_name | 50 images | 500 images | 1000 images | 2000 images | 2kimg-1cpu-compile | 2kimg-1cpu-optimize_for_inference\n",
    "---------- | --------- | ---------- | ----------- | ----------- | --------- | ----\n",
    "mobilenetv3_large_100 | 0m02s |  0m8s | 0m12s | 0m25s | 8m05s | OOM\n",
    "vit_small_patch14_reg4_dinov2.lvd142m | 0m26s | 4m26s | 8m52s | 17m17s | 29m03s | -\n",
    "vit_base_patch14_reg4_dinov2.lvd142m | 1m20s | 11m48s | 23m29s | OOM | OOM | -\n",
    "vit_large_patch14_reg4_dinov2.lvd142m | 4m04s | 38m30s | OOM | OOM | - | -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "MODEL_NAME = \"mobilenetv3_large_100\"\n",
    "EmbedImagesWithModel = EmbedImages.with_init_args(MODEL_NAME)\n",
    "\n",
    "images_df = images_df.with_column(\"embed\", EmbedImagesWithModel(daft.col(\"image\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference device: cpu with dtype: torch.float32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64737faf6c934c9b988a7e6a1037a34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üó°Ô∏è üêü Project: 00:00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486d25f8f5d54394a9a24c8bcc55774a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üó°Ô∏è üêü Project: 00:00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# %%memray_flamegraph --native --max-memory-records 20\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m images_df \u001b[38;5;241m=\u001b[39m \u001b[43mimages_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/api_annotations.py:26\u001b[0m, in \u001b[0;36mDataframePublicAPI.<locals>._wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m type_check_function(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     25\u001b[0m timed_method \u001b[38;5;241m=\u001b[39m time_df_method(func)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtimed_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/analytics.py:199\u001b[0m, in \u001b[0;36mtime_df_method.<locals>.tracked_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    201\u001b[0m     _ANALYTICS_CLIENT\u001b[38;5;241m.\u001b[39mtrack_df_method_call(\n\u001b[1;32m    202\u001b[0m         method_name\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, duration_seconds\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start, error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    203\u001b[0m     )\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/dataframe/dataframe.py:2820\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self, num_preview_rows)\u001b[0m\n\u001b[1;32m   2807\u001b[0m \u001b[38;5;129m@DataframePublicAPI\u001b[39m\n\u001b[1;32m   2808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollect\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_preview_rows: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes the entire DataFrame and materializes the results.\u001b[39;00m\n\u001b[1;32m   2810\u001b[0m \n\u001b[1;32m   2811\u001b[0m \u001b[38;5;124;03m    .. NOTE::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2818\u001b[0m \u001b[38;5;124;03m        DataFrame: DataFrame with materialized results.\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2820\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_materialize_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2822\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2823\u001b[0m     dataframe_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result)\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/dataframe/dataframe.py:2802\u001b[0m, in \u001b[0;36mDataFrame._materialize_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2800\u001b[0m context \u001b[38;5;241m=\u001b[39m get_context()\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_cache \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_builder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2803\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m   2804\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/runners/native_runner.py:59\u001b[0m, in \u001b[0;36mNativeRunner.run\u001b[0;34m(self, builder)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, builder: LogicalPlanBuilder) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PartitionCacheEntry:\n\u001b[0;32m---> 59\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     result_pset \u001b[38;5;241m=\u001b[39m LocalPartitionSet()\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%memray_flamegraph --native --max-memory-records 20\n",
    "\n",
    "images_df = images_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "shutil.rmtree(tmp_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
