{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import shutil\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import daft\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from humanize import naturalsize\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easy timestamps\n",
    "logger.remove()\n",
    "logger.add(sys.stdout, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swap daft's download->decode for pillow's open\n",
    "\n",
    "Adapt [test 21 notebook (torch vs. daft-to-torch)](https://github.com/fr1ll/bedmap-dev/blob/clearer-atlas/nbs/daft-try/21_compare-daft-to-torch-data_clean.ipynb):\n",
    "- add concurrency level parameter for parity with nb 22, but keep as None (default)\n",
    "- Use Pillow to do image open in daft as suggested by Colin Ho in slack discussion\n",
    "\n",
    "So far:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set variables for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_DAFT: bool = True # else use torch dataset\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MODEL_NAME = \"vit_small_patch14_reg4_dinov2.lvd142m\"\n",
    "TEST_DATASET = \"kvriza8/microscopy_images\"\n",
    "NUM_TEST_IMAGES = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define way to download small test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_hf_images(dataset_name: str = \"kvriza8/microscopy_images\",\n",
    "                 dir: Path = None,\n",
    "                 max_images: int = 64,\n",
    "                 overwrite: bool = True,\n",
    "                 format: str = \"png\") -> None:\n",
    "\n",
    "    dataset = load_dataset(dataset_name, split=\"train\", streaming=True)\n",
    "    if overwrite:\n",
    "        shutil.rmtree(dir, ignore_errors=True)\n",
    "        dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    image_paths = []\n",
    "    for i, img_row in enumerate(tqdm(iter(dataset), total=max_images)):\n",
    "        if i >= max_images:\n",
    "            break\n",
    "        img = img_row[\"image\"]\n",
    "        image_paths += [(dir / f\"{i}.{format}\")]\n",
    "        img.save(image_paths[-1])\n",
    "\n",
    "    print(f\"Size of images on disk: {naturalsize(sum([p.stat().st_size for p in image_paths]))}\")\n",
    "\n",
    "    del dataset\n",
    "    gc.collect()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define timm-based embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Embedder:\n",
    "    \"\"\"instantiate pretrained timm model to generate embeddings\"\"\"\n",
    "    def __init__(self, model_name: str, device: torch.device = None):\n",
    "        self.model_name = model_name\n",
    "        # choose device and dtype\n",
    "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if self.device.type == \"cuda\":\n",
    "            self.dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "        else:\n",
    "            self.dtype = torch.float32\n",
    "\n",
    "        # Create and prepare the model\n",
    "        self.model = timm.create_model(self.model_name, pretrained=True, num_classes=0)\n",
    "        self.model.to(self.device, memory_format=torch.channels_last)\n",
    "        self.model.eval()\n",
    "        self.model = torch.compile(self.model, dynamic=True, mode=\"reduce-overhead\")\n",
    "\n",
    "        # must resolve config to drop unneeded fields\n",
    "        cfg = timm.data.resolve_data_config(self.model.pretrained_cfg)\n",
    "        self.transform = timm.data.create_transform(**cfg)\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def embed(self, batch_imgs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"set up input and embed it\"\"\"\n",
    "        batch_imgs = batch_imgs.to(self.device, non_blocking=True, memory_format=torch.channels_last)\n",
    "        if self.device.type == \"cuda\":\n",
    "            with torch.amp.autocast(\"cuda\", dtype=self.dtype):\n",
    "                return self.model(batch_imgs)\n",
    "        return self.model(batch_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define two types of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@daft.udf(return_dtype=daft.DataType.python(), batch_size=BATCH_SIZE)\n",
    "class LoadPillowTransformDaft:\n",
    "    \"\"\"run timm embedder on an image column\"\"\"\n",
    "    def __init__(self, transform: callable, ):\n",
    "        self.transform = transform\n",
    "        # self._pil_load = lambda x: Image.open(x).convert(\"RGB\")\n",
    "\n",
    "    def __call__(self, batch_paths: daft.Series) -> list:\n",
    "        # return [self.transform(Image.open(p).convert(\"RGB\")) for p in batch_paths.to_pylist()]\n",
    "        batch_paths = batch_paths.to_pylist()\n",
    "        logger.info(f\"Number of paths: {len(batch_paths)}\")\n",
    "        last_im = batch_paths[-1]\n",
    "        logger.info(f\"Last image at {last_im} exists? {'Yes' if Path(last_im).exists else 'No'}\")\n",
    "        logger.info(f\"Display: {Image.open(last_im).convert('RGB')}\")\n",
    "        transformed = []\n",
    "        for p in batch_paths:\n",
    "            im = Image.open(p).convert(\"RGB\")\n",
    "            transformed += [self.transform(im)]\n",
    "\n",
    "        return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TorchImageIterAsDict(Dataset):\n",
    "    def __init__(self, filelist: list[Path], transform: callable):\n",
    "        self.filelist = filelist\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image = Image.open(self.filelist[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            return {\"image_transformed\": self.transform(image)}\n",
    "        # return as dict for easy comparison vs. daft\n",
    "        else:\n",
    "            return {\"image\": [image]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daft_to_torch_iter_from_glob(image_glob: str, transform: callable,\n",
    "                                 num_concurr: int | None):\n",
    "    \"\"\"generate a torch image dataset via daft from a glob\"\"\"\n",
    "\n",
    "    images_df = daft.from_glob_path(image_glob)\n",
    "\n",
    "    TransformFromPilForModel = LoadPillowTransformDaft.with_init_args(transform=transform).with_concurrency(num_concurr)\n",
    "    images_df = images_df.with_column(\"image_transformed\", TransformFromPilForModel(daft.col(\"path\"))\n",
    "                                    ).exclude(\"num_rows\")\n",
    "    return images_df.to_torch_iter_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_iter_from_glob(image_glob: str, transform: callable):\n",
    "    \"\"\"generate a torch image dataset via daft from a glob\"\"\"\n",
    "\n",
    "    image_list = [Path(p) for p in glob(image_glob)]\n",
    "    return TorchImageIterAsDict(image_list, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Embedding computation pipeline including dataset instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(model_name: str, images_glob: str, batch_size: int = BATCH_SIZE,\n",
    "                       dataset_type: str = \"plain_torch\", daft_nconcurr: int | None = 1\n",
    "                       ) -> list[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Return a list of embeddings from a glob of images.\n",
    "    Uses a timm pretrained model to generate embeddings\n",
    "    \"\"\"\n",
    "    logger.info(\"Instantiating embedding model.\")\n",
    "    embedder = Embedder(model_name=model_name)\n",
    "\n",
    "    logger.info(f\"Creating dataset of type {dataset_type}.\")\n",
    "    if dataset_type == \"daft_to_torch\":\n",
    "        dataset = daft_to_torch_iter_from_glob(images_glob, embedder.transform, daft_nconcurr)\n",
    "    elif dataset_type == \"plain_torch\":\n",
    "        dataset = torch_iter_from_glob(images_glob, embedder.transform)\n",
    "    else:\n",
    "        raise ValueError(\"Dataset type must be `daft_to_torch` or `plain_torch`.\")\n",
    "\n",
    "    logger.info(\"Creating dataloader.\")\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    logger.info(\"Generating embeddings.\")\n",
    "    for i, batch_images in enumerate(tqdm(dataloader, unit_scale=BATCH_SIZE)):\n",
    "        emb = embedder.embed(batch_images[\"image_transformed\"]).cpu().numpy()\n",
    "        # if i == 0:\n",
    "        #     print(f\"Shape of embedding for one batch: {emb.shape}\")\n",
    "        embeddings.append(emb)\n",
    "    logger.info(\"Stacking embeddings.\")\n",
    "    embeddings = np.vstack(embeddings)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Do memory profiling with one type of dataset\n",
    "\n",
    "Results written near top of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memray extension is already loaded. To reload it, use:\n",
      "  %reload_ext memray\n"
     ]
    }
   ],
   "source": [
    "%load_ext memray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-16 14:49:46.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mDownloading test images.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:12<00:00, 19.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of images on disk: 19.5 MB\n",
      "\u001b[32m2025-03-16 14:50:00.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mStarting embedding pipeline.\u001b[0m\n",
      "\u001b[32m2025-03-16 14:50:00.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_embeddings\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mInstantiating embedding model.\u001b[0m\n",
      "\u001b[32m2025-03-16 14:50:00.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_embeddings\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mCreating dataset of type daft_to_torch.\u001b[0m\n",
      "\u001b[32m2025-03-16 14:50:00.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_embeddings\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mCreating dataloader.\u001b[0m\n",
      "\u001b[32m2025-03-16 14:50:00.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_embeddings\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mGenerating embeddings.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-16 14:50:00.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mNumber of paths: 32\u001b[0m\n",
      "\u001b[32m2025-03-16 14:50:00.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mLast image at file:///tmp/tmp46sywt4f/224.png exists? Yes\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error when running pipeline node Project\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "User-defined function `<__main__.LoadPillowTransformDaft object at 0x7fbd340cba10>` failed when executing on inputs with lengths: (32,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/udf.py:149\u001b[39m, in \u001b[36mrun_udf\u001b[39m\u001b[34m(func, bound_args, evaluated_expressions, py_return_dtype, batch_size)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     results.append(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m user_function_exception:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mLoadPillowTransformDaft.__call__\u001b[39m\u001b[34m(self, batch_paths)\u001b[39m\n\u001b[32m     13\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLast image at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_im\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m exists? \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mYes\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mPath(last_im).exists\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mNo\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDisplay: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_im\u001b[49m\u001b[43m)\u001b[49m.convert(\u001b[33m'\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m transformed = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/PIL/Image.py:3465\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m-> \u001b[39m\u001b[32m3465\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3466\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'file:///tmp/tmp46sywt4f/224.png'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m imglob = tmp+\u001b[33m\"\u001b[39m\u001b[33m/*.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mStarting embedding pipeline.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m embeddings = \u001b[43mcompute_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mimages_glob\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimglob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mdaft_nconcurr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONCURRENCY_LEVEL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mDone with embedding pipeline.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mcompute_embeddings\u001b[39m\u001b[34m(model_name, images_glob, batch_size, dataset_type, daft_nconcurr)\u001b[39m\n\u001b[32m     22\u001b[39m embeddings = []\n\u001b[32m     24\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mGenerating embeddings.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_images\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43memb\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43membedder\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_images\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage_transformed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# if i == 0:\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     print(f\"Shape of embedding for one batch: {emb.shape}\")\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:33\u001b[39m, in \u001b[36m_IterableDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m         data.append(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     35\u001b[39m         \u001b[38;5;28mself\u001b[39m.ended = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/dataframe/dataframe.py:369\u001b[39m, in \u001b[36mDataFrame.iter_rows\u001b[39m\u001b[34m(self, results_buffer_size, column_format)\u001b[39m\n\u001b[32m    364\u001b[39m partitions_iter = context.get_or_create_runner().run_iter_tables(\n\u001b[32m    365\u001b[39m     \u001b[38;5;28mself\u001b[39m._builder, results_buffer_size=results_buffer_size\n\u001b[32m    366\u001b[39m )\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# Iterate through partitions.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpartitions_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumn_format\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpython\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpython_iter_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/runners/native_runner.py:93\u001b[39m, in \u001b[36mNativeRunner.run_iter_tables\u001b[39m\u001b[34m(self, builder, results_buffer_size)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_iter_tables\u001b[39m(\n\u001b[32m     91\u001b[39m     \u001b[38;5;28mself\u001b[39m, builder: LogicalPlanBuilder, results_buffer_size: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     92\u001b[39m ) -> Iterator[MicroPartition]:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_buffer_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults_buffer_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/runners/native_runner.py:88\u001b[39m, in \u001b[36mNativeRunner.run_iter\u001b[39m\u001b[34m(self, builder, results_buffer_size)\u001b[39m\n\u001b[32m     81\u001b[39m executor = NativeExecutor()\n\u001b[32m     82\u001b[39m results_gen = executor.run(\n\u001b[32m     83\u001b[39m     builder,\n\u001b[32m     84\u001b[39m     {k: v.values() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._part_set_cache.get_all_partition_sets().items()},\n\u001b[32m     85\u001b[39m     daft_execution_config,\n\u001b[32m     86\u001b[39m     results_buffer_size,\n\u001b[32m     87\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m results_gen\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/execution/native_executor.py:39\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdaft\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunners\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartitioning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LocalMaterializedResult\n\u001b[32m     34\u001b[39m psets_mp = {\n\u001b[32m     35\u001b[39m     part_id: [part.micropartition()._micropartition \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m parts] \u001b[38;5;28;01mfor\u001b[39;00m part_id, parts \u001b[38;5;129;01min\u001b[39;00m psets.items()\n\u001b[32m     36\u001b[39m }\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mLocalMaterializedResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMicroPartition\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_from_pymicropartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_builder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsets_mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaft_execution_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_buffer_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/udf.py:151\u001b[39m, in \u001b[36mrun_udf\u001b[39m\u001b[34m(func, bound_args, evaluated_expressions, py_return_dtype, batch_size)\u001b[39m\n\u001b[32m    149\u001b[39m             results.append(func(*args, **kwargs))\n\u001b[32m    150\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m user_function_exception:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    152\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUser-defined function `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` failed when executing on inputs with lengths: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(cur_batch_size\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39m_\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mevaluated_expressions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    153\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01muser_function_exception\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# HACK: Series have names and the logic for naming fields/series in a UDF is to take the first\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;66;03m# Expression's name. Note that this logic is tied to the `to_field` implementation of the Rust PythonUDF\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;66;03m# and is quite error prone! If our Series naming logic here is wrong, things will break when the UDF is run on a table.\u001b[39;00m\n\u001b[32m    158\u001b[39m name = evaluated_expressions[\u001b[32m0\u001b[39m].name()\n",
      "\u001b[31mRuntimeError\u001b[39m: User-defined function `<__main__.LoadPillowTransformDaft object at 0x7fbd340cba10>` failed when executing on inputs with lengths: (32,)"
     ]
    }
   ],
   "source": [
    "# %%memray_flamegraph --native --follow-fork --temporal\n",
    "\n",
    "USE_DAFT = True\n",
    "CONCURRENCY_LEVEL = None\n",
    "ds_type = \"daft_to_torch\" if USE_DAFT else \"plain_torch\"\n",
    "\n",
    "with TemporaryDirectory() as tmp:\n",
    "    logger.info(\"Downloading test images.\")\n",
    "    dl_hf_images(dir=Path(tmp), max_images=NUM_TEST_IMAGES)\n",
    "    imglob = tmp+\"/*.png\"\n",
    "    logger.info(\"Starting embedding pipeline.\")\n",
    "    embeddings = compute_embeddings(model_name=MODEL_NAME,\n",
    "                                    images_glob = imglob,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    dataset_type=ds_type,\n",
    "                                    daft_nconcurr=CONCURRENCY_LEVEL)\n",
    "    logger.info(\"Done with embedding pipeline.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
