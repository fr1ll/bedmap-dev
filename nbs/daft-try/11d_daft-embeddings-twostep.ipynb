{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp daft_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willsa/git/bedmap-dev/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "import daft\n",
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from einops import rearrange\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "daft.set_execution_config(enable_native_executor=True,\n",
    "                        #   default_morsel_size=50\n",
    "                          )\n",
    "\n",
    "MAX_IMAGES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:04, 11.59it/s]\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "tmp_path = Path(\"./tmp-test-images\")\n",
    "tmp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset_name = \"kvriza8/microscopy_images\"\n",
    "\n",
    "dataset = load_dataset(dataset_name, split=\"train\", streaming=True)\n",
    "\n",
    "for i, example in enumerate(tqdm(iter(dataset))):  # Use iterator to avoid full load\n",
    "    if i >= MAX_IMAGES:\n",
    "        break\n",
    "    image = example[\"image\"]\n",
    "    image.save(tmp_path / f\"{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@dataclass\n",
    "class TimmEmbedder:\n",
    "    \"\"\"\n",
    "    embed an image with any timm model that supports this\n",
    "\n",
    "    Reference: https://huggingface.co/docs/timm/main/en/feature_extraction#pooled\n",
    "    \"\"\"\n",
    "    model_name: str\n",
    "    device: torch.device = field(init=False)\n",
    "    dtype: torch.dtype = field(init=False)\n",
    "    _model: Callable = field(init=False)\n",
    "    _transforms: Callable = field(init=False)\n",
    "\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # initialize model and transforms\n",
    "        self._model = timm.create_model(self.model_name, pretrained=True, num_classes=0)\n",
    "        cfg = self._model.pretrained_cfg\n",
    "        self._transform = timm.data.create_transform(**timm.data.resolve_data_config(cfg))\n",
    "\n",
    "        # set device and dtype\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dtype = torch.bfloat16 if self.device.type == \"cuda\" and torch.cuda.is_bf16_supported() else (\n",
    "            torch.float16 if self.device.type == \"cuda\" else torch.float32\n",
    "        )\n",
    "        print(f\"Inference device: {self.device} with dtype: {self.dtype}\")\n",
    "\n",
    "        # optimize model for inference\n",
    "        self._model = self._model.eval().to(device=self.device, dtype=self.dtype)\n",
    "        self._model = torch.jit.optimize_for_inference(torch.jit.script(self._model))\n",
    "\n",
    "\n",
    "    def __call__(self, image: torch.Tensor | Image.Image) -> np.array:\n",
    "            \"\"\"transform image, run inference, extract embedding as 1D array\"\"\"\n",
    "            image = self._transform(image).to(self.device, self.dtype).unsqueeze(0)\n",
    "            emb = self._model(image)\n",
    "            return emb.detach().cpu().float().numpy().squeeze()\n",
    "\n",
    "    def transform(self, image: torch.Tensor | Image.Image) -> torch.Tensor:\n",
    "         \"\"\"transform image\"\"\"\n",
    "         return self._transform(image).to(self.device, self.dtype).unsqueeze(0)\n",
    "\n",
    "    def embed(self, img_tensor: torch.Tensor) -> np.array:\n",
    "         \"\"\"embed tensor of already-transformed images\"\"\"\n",
    "         return self._model(img_tensor).detach().cpu().float().numpy().squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference device: cpu with dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "# it's a one-stop shop\n",
    "e = TimmEmbedder(\"mobilenetv3_large_100\")\n",
    "e(torch.rand((3,256,256)))\n",
    "\n",
    "# or do in two steps\n",
    "\n",
    "t = e.transform(torch.rand((3,256,256)))\n",
    "v = e.embed(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@daft.udf(return_dtype=daft.DataType.list(daft.DataType.float32()))\n",
    "def transform_images(images_col, embedder: Callable) -> list:\n",
    "    images = [rearrange(im, \"h w c -> c h w\") for im in images_col.to_pylist()]\n",
    "    return [embedder.transform(\n",
    "        torch.tensor(im, dtype=embedder.dtype)) for im in images]\n",
    "\n",
    "#| export\n",
    "\n",
    "@daft.udf(return_dtype=daft.DataType.list(daft.DataType.float32()))\n",
    "def embed_images(images_col, embedder: Callable) -> list:\n",
    "    images = [rearrange(im, \"h w c -> c h w\") for im in images_col.to_pylist()]\n",
    "    return [embedder.embed(\n",
    "        torch.tensor(im, dtype=embedder.dtype)) for im in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: I need to figure out how to create two udfs that work together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "glob = tmp_path.as_posix() +\"/*.png\"\n",
    "images_df = daft.from_glob_path(glob).with_column_renamed(\"path\", \"path_full_img\")\n",
    "\n",
    "images_df = images_df.with_column(\"image\", daft.col(\"path_full_img\"\n",
    "                                 ).url.download().image.decode(\n",
    "                                     mode=\"RGB\", on_error=\"null\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference time for some embedding models on CPU on my laptop\n",
    "\n",
    "model_name | 50 images | 500 images | 1000 images | 2000 images\n",
    "---------- | --------- | ---------- | ----------- | -----------\n",
    "mobilenetv3_large_100 | 0m02s |  0m8s | 0m12s | 0m25s\n",
    "vit_base_patch14_reg4_dinov2.lvd142m | 1m20s | 11m48s | 23m29s | OOM\n",
    "vit_large_patch14_reg4_dinov2.lvd142m | 4m04s | 38m30s | OOM | OOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference device: cpu with dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "MODEL_NAME = \"mobilenetv3_large_100\"\n",
    "embedder = TimmEmbedder(MODEL_NAME)\n",
    "\n",
    "images_df = images_df.with_column(\"transform\", transform_images(daft.col(\"image\"), embedder))\n",
    "images_df = images_df.with_column(\"embed\", embed_images(daft.col(\"transform\"), embedder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "thread '<unnamed>' panicked at /home/runner/work/Daft/Daft/src/daft-dsl/src/pyobj_serde.rs:39:22:\n",
      "Pickling error occurred when computing hash of Pyobject: Custom(\"RuntimeError: Tried to serialize object __torch__.timm.models.mobilenetv3.___torch_mangle_361.MobileNetV3 which does not have a __getstate__ method defined!\")\n"
     ]
    },
    {
     "ename": "PanicException",
     "evalue": "Pickling error occurred when computing hash of Pyobject: Custom(\"RuntimeError: Tried to serialize object __torch__.timm.models.mobilenetv3.___torch_mangle_361.MobileNetV3 which does not have a __getstate__ method defined!\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPanicException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| hide\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m images_df \u001b[38;5;241m=\u001b[39m \u001b[43mimages_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/api_annotations.py:26\u001b[0m, in \u001b[0;36mDataframePublicAPI.<locals>._wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m type_check_function(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     25\u001b[0m timed_method \u001b[38;5;241m=\u001b[39m time_df_method(func)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtimed_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/analytics.py:199\u001b[0m, in \u001b[0;36mtime_df_method.<locals>.tracked_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    201\u001b[0m     _ANALYTICS_CLIENT\u001b[38;5;241m.\u001b[39mtrack_df_method_call(\n\u001b[1;32m    202\u001b[0m         method_name\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, duration_seconds\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start, error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    203\u001b[0m     )\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/dataframe/dataframe.py:2820\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self, num_preview_rows)\u001b[0m\n\u001b[1;32m   2807\u001b[0m \u001b[38;5;129m@DataframePublicAPI\u001b[39m\n\u001b[1;32m   2808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollect\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_preview_rows: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes the entire DataFrame and materializes the results.\u001b[39;00m\n\u001b[1;32m   2810\u001b[0m \n\u001b[1;32m   2811\u001b[0m \u001b[38;5;124;03m    .. NOTE::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2818\u001b[0m \u001b[38;5;124;03m        DataFrame: DataFrame with materialized results.\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2820\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_materialize_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2822\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2823\u001b[0m     dataframe_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result)\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/dataframe/dataframe.py:2802\u001b[0m, in \u001b[0;36mDataFrame._materialize_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2800\u001b[0m context \u001b[38;5;241m=\u001b[39m get_context()\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_cache \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_builder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2803\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m   2804\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/runners/native_runner.py:59\u001b[0m, in \u001b[0;36mNativeRunner.run\u001b[0;34m(self, builder)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, builder: LogicalPlanBuilder) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PartitionCacheEntry:\n\u001b[0;32m---> 59\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     result_pset \u001b[38;5;241m=\u001b[39m LocalPartitionSet()\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/runners/native_runner.py:77\u001b[0m, in \u001b[0;36mNativeRunner.run_iter\u001b[0;34m(self, builder, results_buffer_size)\u001b[0m\n\u001b[1;32m     74\u001b[0m daft_execution_config \u001b[38;5;241m=\u001b[39m get_context()\u001b[38;5;241m.\u001b[39mdaft_execution_config\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Optimize the logical plan.\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m builder \u001b[38;5;241m=\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m executor \u001b[38;5;241m=\u001b[39m NativeExecutor()\n\u001b[1;32m     79\u001b[0m results_gen \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m     80\u001b[0m     builder,\n\u001b[1;32m     81\u001b[0m     {k: v\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_part_set_cache\u001b[38;5;241m.\u001b[39mget_all_partition_sets()\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[1;32m     82\u001b[0m     daft_execution_config,\n\u001b[1;32m     83\u001b[0m     results_buffer_size,\n\u001b[1;32m     84\u001b[0m )\n",
      "File \u001b[0;32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/logical/builder.py:112\u001b[0m, in \u001b[0;36mLogicalPlanBuilder.optimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LogicalPlanBuilder:\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize the underlying logical plan.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     builder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LogicalPlanBuilder(builder)\n",
      "\u001b[0;31mPanicException\u001b[0m: Pickling error occurred when computing hash of Pyobject: Custom(\"RuntimeError: Tried to serialize object __torch__.timm.models.mobilenetv3.___torch_mangle_361.MobileNetV3 which does not have a __getstate__ method defined!\")"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "images_df = images_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "import shutil\n",
    "shutil.rmtree(tmp_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
