{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "from collections.abc import Callable\n",
    "\n",
    "import daft\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOB_PATH = \"../tests/test-data/butterflies_baseline/data/originals/*.jpg\"\n",
    "MIN_BYTES = 100\n",
    "MIN_ASPECT = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willsa/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/context.py:168: UserWarning: Daft is configured to use the new NativeRunner by default as of v0.4.0. If you are encountering any regressions, please switch back to the legacy PyRunner via `daft.context.set_runner_py()` or by setting the env variable `DAFT_RUNNER=py`. We appreciate you filing issues and helping make the NativeRunner better: https://github.com/Eventual-Inc/Daft/issues\n",
      "  warnings.warn(\n",
      "/home/willsa/git/bedmap-dev/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "df_img = daft.from_glob_path(GLOB_PATH).with_column_renamed(\"path\", \"img_path\")\n",
    "\n",
    "# drop any files too small to be images\n",
    "df_img = df_img.filter(df_img[\"size\"] > MIN_BYTES)\n",
    "\n",
    "# create image name column\n",
    "df_img = df_img.with_column(\"img_name\",\n",
    "                   df_img[\"img_path\"].str.split(\"/\").list.get(\n",
    "                       -1).cast(str))\n",
    "\n",
    "# get the images since we'll need to use them several times\n",
    "df_img = df_img.with_column(\"img\", daft.col(\"img_path\"\n",
    "                                   ).url.download(on_error=\"null\"\n",
    "                                                  ).image.decode(on_error=\"null\",\n",
    "                                                                 mode=\"RGB\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_on_condition(df: daft.DataFrame, condition: Callable[[daft.DataFrame], daft.DataFrame]):\n",
    "    \"\"\"Splits a DataFrame into accepted and dropped rows based on a filtering condition.\n",
    "\n",
    "    Args:\n",
    "        df (daft.DataFrame): The input DataFrame.\n",
    "        condition (Callable[[daft.DataFrame], daft.DataFrame]): A function that filters the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[daft.DataFrame, daft.DataFrame]: (accepted_df, dropped_df)\n",
    "    \"\"\"\n",
    "    filtered_df = condition(df)\n",
    "    dropped_df = filtered_df.except_distinct(df)\n",
    "    return filtered_df, dropped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filtering functions\n",
    "def size_nontrivial(df: daft.DataFrame) -> daft.DataFrame:\n",
    "    \"\"\"Keeps images that are at least MIN_BYTES in size on disk.\"\"\"\n",
    "    return df.filter(df[\"size\"] > MIN_BYTES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_not_oblong(arr: np.ndarray, max_oblongness: float=4.0) -> bool:\n",
    "    \"\"\"is an array oblong\"\"\"\n",
    "    h, w, _ = arr.shape\n",
    "    oblongness = np.max([h/w, w/h])\n",
    "    return oblongness < max_oblongness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrs = [np.zeros((3,4,2)), np.zeros((1,3,1)), np.zeros((5,3,2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 4, 2), (1, 3, 1), (5, 3, 2)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes = [a.shape for a in arrs]\n",
    "\n",
    "aspects = [np.max([h/w, w/h]) for h, w, c for s in shapes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "daft.udf(return_dtype=daft.DataType.bool())\n",
    "def array_not_oblong_udf(arrs: daft.Series, max_oblongness: float=4.0) -> bool:\n",
    "    \"\"\"is an array oblong\"\"\"\n",
    "    arrs = arrs.to_pylist()\n",
    "    shapes = np.array([a.shape[:2] for a in arrs])  # Extract h, w as an array\n",
    "    max_aspects = np.max(shapes / shapes[:, ::-1], axis=1)  # Compute max(h/w, w/h)\n",
    "    return max_aspects < max_oblongness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_not_oblong(df: daft.DataFrame) -> daft.DataFrame:\n",
    "    \"\"\"Keeps images with an aspect ratio between 1:4 and 4:1 using Daft's `image_decode`.\"\"\"\n",
    "    decoded = df.with_column(\"decoded_img\", daft.col(\"img_path\").url.download(on_error=\"null\")\n",
    "                             .image.decode(on_error=\"null\"))\n",
    "    # checkable = decoded.with_column(\"is_not_oblong\", df[\"img\"].apply(array_not_oblong, daft.DataType.bool()))\n",
    "    checkable = decoded.with_column(\"is_not_oblong\", array_not_oblong_udf(df_img.select(\"img\")))\n",
    "    checked = checkable.filter(checkable[\"is_not_oblong\"]\n",
    "                             ).exclude(\"is_not_oblong\", \"decoded_img\") # Drop transient columns\n",
    "    return checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Expression' object has no attribute 'collect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43mdf_img\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Expression' object has no attribute 'collect'"
     ]
    }
   ],
   "source": [
    "type(df_img[\"img_path\"].collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mimg_not_oblong\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_img\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m, in \u001b[0;36mimg_not_oblong\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m decoded \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwith_column(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoded_img\u001b[39m\u001b[38;5;124m\"\u001b[39m, daft\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_path\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39murl\u001b[38;5;241m.\u001b[39mdownload(on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnull\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m                          \u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mdecode(on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnull\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# checkable = decoded.with_column(\"is_not_oblong\", df[\"img\"].apply(array_not_oblong, daft.DataType.bool()))\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m checkable \u001b[38;5;241m=\u001b[39m decoded\u001b[38;5;241m.\u001b[39mwith_column(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_not_oblong\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43marray_not_oblong_udf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m checked \u001b[38;5;241m=\u001b[39m checkable\u001b[38;5;241m.\u001b[39mfilter(checkable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_not_oblong\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m                          )\u001b[38;5;241m.\u001b[39mexclude(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_not_oblong\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoded_img\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Drop transient columns\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m checked\n",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m, in \u001b[0;36marray_not_oblong_udf\u001b[0;34m(arrs, max_oblongness)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"is an array oblong\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m arrs \u001b[38;5;241m=\u001b[39m arrs\u001b[38;5;241m.\u001b[39mto_pylist()\n\u001b[0;32m----> 5\u001b[0m shapes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrs])  \u001b[38;5;66;03m# Extract h, w as an array\u001b[39;00m\n\u001b[1;32m      6\u001b[0m max_aspects \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(shapes \u001b[38;5;241m/\u001b[39m shapes[:, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Compute max(h/w, w/h)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m max_aspects \u001b[38;5;241m<\u001b[39m max_oblongness\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "img_not_oblong(df_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_name_distinct(df: daft.DataFrame, name_col: str=\"img_name\") -> daft.DataFrame:\n",
    "    \"\"\"Keeps images with unique filenames.\"\"\"\n",
    "    aggs = [daft.col(c).any_value() for c in set(df_img.column_names) - {name_col}]\n",
    "    return df.groupby(name_col).agg(*aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define pipeline of conditions\n",
    "pipeline: list[Callable[[daft.DataFrame], daft.DataFrame]] = [\n",
    "    size_nontrivial,\n",
    "    img_not_oblong,\n",
    "    img_name_distinct\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the pipeline\n",
    "for condition in pipeline:\n",
    "    print(f\"Checking {condition.__qualname__}\")\n",
    "    df_img, dropped = split_on_condition(df_img, condition)\n",
    "\n",
    "    n_dropped = dropped.count_rows()\n",
    "\n",
    "    if n_dropped > 0:\n",
    "        print(f\"Dropped {n_dropped} rows due to {condition.__name__}:\")\n",
    "        print(dropped.head(1))  # Print first dropped row as an example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
