{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp embed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from transformers import pipeline\n",
    "import daft\n",
    "\n",
    "from bedmap.config import Cfg\n",
    "from bedmap.step import step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def images_from_paths(pathlist):\n",
    "    return (Image.open(p.as_posix()).convert(\"RGB\").copy() for p in pathlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def embed_images(imagepaths : list[Path],\n",
    "                 model_name : str = \"timm/vit_small_patch14_reg4_dinov2.lvd142m\",\n",
    "                 batch_size : int = 4\n",
    "                 ) -> list[np.array]:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    pipe = pipeline(task=\"image-feature-extraction\",\n",
    "                    model=model_name, device=device, pool=True, use_fast=True)\n",
    "\n",
    "    # logger.info(\"Starting embedding pipeline.\")\n",
    "    embeddings = []\n",
    "\n",
    "    for out in tqdm(pipe(images_from_paths(imagepaths), batch_size=batch_size),\n",
    "                    total=len(imagepaths)//batch_size):\n",
    "        embeddings += out\n",
    "\n",
    "    # logger.info(\"Done with embedding pipeline.\")\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = daft.from_pydict({\"img_path\": [\"file://cae.\", \"file:////acea/\"]})\n",
    "# df = df.with_column(\"img_path_trim\",\n",
    "#                     df[\"img_path\"].str.replace(pattern=\"^file:/+\", replacement=\"/\", regex=True)\n",
    "#                    )\n",
    "# df.select(daft.col(\"img_path_trim\")).to_pylist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@step(requires=[\"img_path\"], provides=[\"embeddings\"])\n",
    "def create_embeddings_col(df: daft.DataFrame, model_name: str, batch_size: int) -> daft.DataFrame:\n",
    "    \"\"\"\n",
    "    Embed images for a given dataframe.\n",
    "    \"\"\"\n",
    "    ## daft encodes paths as URIs, always starting with file://\n",
    "    df = df.with_column(\"img_path_nouri\", df[\"img_path\"].str.replace(\n",
    "        pattern=\"^file://\", replacement=\"\", regex=True))\n",
    "    paths = [Path(r[\"img_path_nouri\"]) for r in df.select(\"img_path_nouri\").to_pylist()]\n",
    "    embeds = embed_images(paths, model_name=model_name, batch_size=batch_size)\n",
    "    # fixed_size_list lets us use normal arrow methods to calculate length later\n",
    "    embeds_type = daft.DataType.fixed_size_list(daft.DataType.float32(), embeds.shape[-1])\n",
    "    embeds_series = daft.Series.from_numpy(embeds).cast(embeds_type)\n",
    "\n",
    "    df_embs = daft.from_pydict({\"embeddings\": embeds_series,\n",
    "    \"img_path_nouri\":  df.select(\"img_path_nouri\").to_arrow()[\"img_path_nouri\"]}\n",
    "    )\n",
    "\n",
    "    df = df.join(df_embs, on=\"img_path_nouri\")\n",
    "\n",
    "    return df.exclude(\"img_path_nouri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a9647fb5af4207bd23d677d2ccafeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üó°Ô∏è üêü InMemorySource: 00:00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e8c943a6b048cea270a89cc95d6947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üó°Ô∏è üêü Project: 00:00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c932084c1e9341638a81d2f0a0e1b83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 0 files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9cb7073463e4a5cb518373fea0c1b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b2be36057e400e9e37302b4cd0f48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "12it [00:06,  1.88it/s]                      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a23113d228e45e7a576b93f090974e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üó°Ô∏è üêü InMemorySource: 00:00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade87d07ca2b4b1d9c67a45961fe57be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üó°Ô∏è üêü Project: 00:00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "from bedmap.prepare_images import df_images_from_pattern\n",
    "from bedmap.config import Cfg\n",
    "\n",
    "cfg = Cfg()\n",
    "TEST_DIR = \"../tests/test-data/smithsonian_butterflies_10/jpgs\"\n",
    "\n",
    "df = df_images_from_pattern(TEST_DIR)\n",
    "df = create_embeddings_col(df, model_name=cfg.model_name, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
