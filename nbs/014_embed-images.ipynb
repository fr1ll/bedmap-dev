{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp embed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from transformers import pipeline\n",
    "import daft\n",
    "\n",
    "from bedmap.config import Cfg\n",
    "from bedmap.step import step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def images_from_paths(pathlist):\n",
    "    return (Image.open(p.as_posix()).convert(\"RGB\").copy() for p in pathlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def embed_images(imagepaths : list[Path],\n",
    "                 model_name : str = \"timm/vit_small_patch14_reg4_dinov2.lvd142m\",\n",
    "                 batch_size : int = 4\n",
    "                 ) -> list[np.array]:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    pipe = pipeline(task=\"image-feature-extraction\",\n",
    "                    model=model_name, device=device, pool=True, use_fast=True)\n",
    "\n",
    "    # logger.info(\"Starting embedding pipeline.\")\n",
    "    embeddings = []\n",
    "\n",
    "    for out in tqdm(pipe(images_from_paths(imagepaths), batch_size=batch_size),\n",
    "                    total=len(imagepaths)//batch_size):\n",
    "        embeddings += out\n",
    "\n",
    "    # logger.info(\"Done with embedding pipeline.\")\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = daft.from_pydict({\"img_path\": [\"file://cae.\", \"file:////acea/\"]})\n",
    "# df = df.with_column(\"img_path_trim\",\n",
    "#                     df[\"img_path\"].str.replace(pattern=\"^file:/+\", replacement=\"/\", regex=True)\n",
    "#                    )\n",
    "# df.select(daft.col(\"img_path_trim\")).to_pylist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@step(requires=[\"img_path\"], provides=[\"embeddings\"])\n",
    "def create_embeddings_col(df: daft.DataFrame, model_name: str, batch_size: int) -> daft.DataFrame:\n",
    "    \"\"\"\n",
    "    Embed images for a given dataframe.\n",
    "    \"\"\"\n",
    "    ## daft encodes paths as URIs, always starting with file://\n",
    "    df = df.with_column(\"img_path_nouri\", df[\"img_path\"].str.replace(\n",
    "        pattern=\"^file://\", replacement=\"\", regex=True))\n",
    "    paths = [Path(r[\"img_path_nouri\"]) for r in df.select(\"img_path_nouri\").to_pylist()]\n",
    "    embeds = embed_images(paths, model_name=model_name, batch_size=batch_size)\n",
    "    # fixed_size_list lets us use normal arrow methods to calculate length later\n",
    "    embeds_type = daft.DataType.fixed_size_list(daft.DataType.float32(), embeds.shape[-1])\n",
    "    embeds_series = daft.Series.from_numpy(embeds).cast(embeds_type)\n",
    "\n",
    "    df_embs = daft.from_pydict({\"embeddings\": embeds_series,\n",
    "    \"img_path_nouri\":  df.select(\"img_path_nouri\").to_arrow()[\"img_path_nouri\"]}\n",
    "    )\n",
    "\n",
    "    df = df.join(df_embs, on=\"img_path_nouri\")\n",
    "\n",
    "    return df.exclude(\"img_path_nouri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willsa/git/bedmap-dev/.venv/lib/python3.12/site-packages/pydantic_settings/main.py:425: UserWarning: Config key `pyproject_toml_table_header` is set in model_config but will be ignored because no PyprojectTomlConfigSettingsSource source is configured. To use this config key, add a PyprojectTomlConfigSettingsSource source to the settings sources via the settings_customise_sources hook.\n",
      "  self._settings_warn_unused_config_keys(sources, self.model_config)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e502a0522743de9860654cd3ae0db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üó°Ô∏è üêü InMemorySource: 00:00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44840208c91f4c3f8bb6316fa2d616a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üó°Ô∏è üêü Project: 00:00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "12it [00:04,  2.73it/s]                      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0575dd06fa9473287c0002c1d60c205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üó°Ô∏è üêü InMemorySource: 00:00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a5160fd66d4f46bbb4ce0e8d7fd0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üó°Ô∏è üêü Project: 00:00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "from bedmap.prepare_images import df_images_from_pattern\n",
    "from bedmap.config import Cfg\n",
    "\n",
    "cfg = Cfg()\n",
    "TEST_DIR = \"../tests/test-data/smithsonian_butterflies_10/jpgs\"\n",
    "\n",
    "df = df_images_from_pattern(TEST_DIR)\n",
    "df = create_embeddings_col(df, model_name=cfg.model_name, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
