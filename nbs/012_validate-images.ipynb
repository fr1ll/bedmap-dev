{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e895044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp validate_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d9e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import daft\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db842e5",
   "metadata": {},
   "source": [
    "## Define validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3291749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "MIN_BYTES = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afe917e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def split_on_condition(df: daft.DataFrame, condition: Callable[[daft.DataFrame], daft.DataFrame]):\n",
    "    \"\"\"Splits a DataFrame into accepted and dropped rows based on a filtering condition.\n",
    "\n",
    "    Args:\n",
    "        df (daft.DataFrame): The input DataFrame.\n",
    "        condition (Callable[[daft.DataFrame], daft.DataFrame]): A function that filters the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[daft.DataFrame, daft.DataFrame]: (accepted_df, dropped_df)\n",
    "    \"\"\"\n",
    "    filtered_df = condition(df)\n",
    "    if filtered_df.count_rows() < df.count_rows():\n",
    "        dropped_df = filtered_df.except_distinct(df)\n",
    "        return filtered_df, dropped_df\n",
    "    else:\n",
    "        return df, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ecbc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "# Define filtering functions\n",
    "def size_nontrivial(df: daft.DataFrame) -> daft.DataFrame:\n",
    "    \"\"\"Keeps images that are at least MIN_BYTES in size on disk.\"\"\"\n",
    "    return df.filter(df[\"size\"] > MIN_BYTES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a334c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@daft.udf(return_dtype=daft.DataType.bool())\n",
    "def array_not_oblong(arrs: daft.Series, max_oblongness: float = 4.0) -> bool:\n",
    "    \"\"\"is an array oblong\"\"\"\n",
    "    arrs = arrs.to_pylist()\n",
    "    shapes = np.array([a.shape[:2] for a in arrs])  # Extract h, w as an array\n",
    "    max_aspects = np.max(shapes / shapes[:, ::-1], axis=1)  # Compute max(h/w, w/h)\n",
    "    return max_aspects < max_oblongness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe6b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def img_not_oblong(df: daft.DataFrame) -> daft.DataFrame:\n",
    "    \"\"\"Keeps images with an aspect ratio between 1:4 and 4:1 using Daft's `image_decode`.\"\"\"\n",
    "    # checkable = decoded.with_column(\"is_not_oblong\", df[\"img\"].apply(array_not_oblong, daft.DataType.bool()))\n",
    "    checkable = df.with_column(\"is_not_oblong\", array_not_oblong(df[\"img\"]))\n",
    "    checked = checkable.filter(checkable[\"is_not_oblong\"]).exclude(\"is_not_oblong\")  # Drop transient column\n",
    "    return checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13a65938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def img_name_distinct(df: daft.DataFrame, name_col: str = \"img_name\") -> daft.DataFrame:\n",
    "    \"\"\"Keeps images with unique filenames.\"\"\"\n",
    "    aggs = [daft.col(c).any_value() for c in set(df.column_names) - {name_col}]\n",
    "    return df.groupby(name_col).agg(*aggs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3b86e8",
   "metadata": {},
   "source": [
    "## Collect validations as pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f570c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def do_validations(df: daft.DataFrame, validations: list[Callable]\n",
    "                    ) -> tuple[daft.DataFrame, daft.DataFrame]:\n",
    "    \"\"\"process checks pipeline\"\"\"\n",
    "    for validation in validations:\n",
    "        print(f\"Checking {validation.__qualname__}\")\n",
    "        df, dropped = split_on_condition(df, validation)\n",
    "\n",
    "        if dropped:\n",
    "            print(f\"{dropped.count_rows()} images failed check for {validation.__name__} and will be dropped.\")\n",
    "            print(dropped.head(1))  # Print first dropped row as an example\n",
    "\n",
    "    return df, dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29f4905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Define pipeline of conditions\n",
    "pipeline: list[Callable[[daft.DataFrame], daft.DataFrame]] = [size_nontrivial, img_not_oblong, img_name_distinct]\n",
    "\n",
    "validate_images = partial(do_validations, validations=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c956b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
