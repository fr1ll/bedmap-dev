{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import shutil\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, IterableDataset\n",
    "from humanize import naturalsize\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from transformers import pipeline\n",
    "from itertools import batched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easy timestamps\n",
    "logger.remove()\n",
    "logger.add(sys.stdout, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set variables for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "MODEL_NAME = \"timm/vit_small_patch14_reg4_dinov2.lvd142m\"\n",
    "TEST_DATASET = \"kvriza8/microscopy_images\"\n",
    "NUM_TEST_IMAGES = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define way to download small test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_hf_images(dataset_name: str = \"kvriza8/microscopy_images\",\n",
    "                 dir: Path = None,\n",
    "                 max_images: int = 64,\n",
    "                 overwrite: bool = True,\n",
    "                 format: str = \"png\") -> None:\n",
    "\n",
    "    dataset = load_dataset(dataset_name, split=\"train\", streaming=True)\n",
    "    if overwrite:\n",
    "        shutil.rmtree(dir, ignore_errors=True)\n",
    "        dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    image_paths = []\n",
    "    for i, img_row in enumerate(tqdm(iter(dataset), total=max_images)):\n",
    "        if i >= max_images:\n",
    "            break\n",
    "        img = img_row[\"image\"]\n",
    "        image_paths += [(dir / f\"{i}.{format}\")]\n",
    "        img.save(image_paths[-1])\n",
    "\n",
    "    print(f\"Size of images on disk: {naturalsize(sum([p.stat().st_size for p in image_paths]))}\")\n",
    "\n",
    "    del dataset\n",
    "    gc.collect()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_images(pathlist):\n",
    "    for p in pathlist:\n",
    "        yield Image.open(p.as_posix()).convert(\"RGB\").copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_from_paths(pathlist):\n",
    "    return (Image.open(p.as_posix()).convert(\"RGB\").copy() for p in pathlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-29 21:25:16.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mDownloading test images.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:16<00:00, 15.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of images on disk: 19.5 MB\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as tmp:    \n",
    "    logger.info(\"Downloading test images.\")\n",
    "    dl_hf_images(dir=Path(tmp), max_images=NUM_TEST_IMAGES)\n",
    "    imagepaths = list(Path(tmp).glob(\"*.png\"))\n",
    "    gen = images_from_paths(imagepaths)\n",
    "    for i in range(1):\n",
    "        im = next(gen)\n",
    "        im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-29 21:11:47.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mDownloading test images.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Memray WARNING: Correcting symbol for malloc from 0x420620 to 0x7f334b469c60\n",
      "Memray WARNING: Correcting symbol for free from 0x420ab0 to 0x7f334b46a370\n",
      "100%|██████████| 256/256 [00:17<00:00, 14.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of images on disk: 19.5 MB\n",
      "\u001b[32m2025-03-29 21:12:07.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mInstantiating pipeline.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-29 21:12:10.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mStarting embedding pipeline.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "256it [03:06,  1.37it/s]                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-29 21:15:17.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mDone with embedding pipeline.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a447dbb496314a56b09681d9c0100a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">⚠ <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> No debug information was found for the Python interpreter </span> ⚠\n",
       "\n",
       "Without debug information reports showing native traces <span style=\"font-weight: bold\">may not include file names and line numbers</span>. Please use an \n",
       "interpreter built with debug symbols for best results. Check <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://bloomberg.github.io/memray/native_mode.html</span> \n",
       "for more information regarding how memray resolves symbols.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "⚠ \u001b[1;33m No debug information was found for the Python interpreter \u001b[0m ⚠\n",
       "\n",
       "Without debug information reports showing native traces \u001b[1mmay not include file names and line numbers\u001b[0m. Please use an \n",
       "interpreter built with debug symbols for best results. Check \u001b[4;94mhttps://bloomberg.github.io/memray/native_mode.html\u001b[0m \n",
       "for more information regarding how memray resolves symbols.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff310144c0546e4a767796f10ce816d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Results saved to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">/home/willsa/git/bedmap-dev/nbs/daft-try/memray-results/tmp482mgjyc/flamegraph.html</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Results saved to \u001b[1;36m/home/willsa/git/bedmap-dev/nbs/daft-try/memray-results/tmp482mgjyc/\u001b[0m\u001b[1;36mflamegraph.html\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"/home/willsa/git/bedmap-dev/nbs/daft-try/memray-results/tmp482mgjyc/flamegraph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f329c310e00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%memray_flamegraph --native --follow-fork --temporal\n",
    "\n",
    "with TemporaryDirectory() as tmp:\n",
    "    logger.info(\"Downloading test images.\")\n",
    "    dl_hf_images(dir=Path(tmp), max_images=NUM_TEST_IMAGES)\n",
    "    imagepaths = list(Path(tmp).glob(\"*.png\"))\n",
    "    embeddings = []\n",
    "\n",
    "    # ds = IterableDataset.from_generator(lambda: stream_images(imagepaths))\n",
    "\n",
    "    logger.info(\"Instantiating pipeline.\")\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    pipe = pipeline(task=\"image-feature-extraction\",\n",
    "                    model=MODEL_NAME, device=DEVICE, pool=True, use_fast=True)\n",
    "            \n",
    "\n",
    "    logger.info(\"Starting embedding pipeline.\")\n",
    "\n",
    "    for out in tqdm(pipe(images_from_paths(imagepaths), batch_size=BATCH_SIZE),\n",
    "                    total=len(imagepaths)//BATCH_SIZE):\n",
    "        embeddings += out\n",
    "\n",
    "    logger.info(\"Done with embedding pipeline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
