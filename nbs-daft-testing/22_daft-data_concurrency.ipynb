{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import shutil\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import daft\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from humanize import naturalsize\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easy timestamps\n",
    "logger.remove()\n",
    "logger.add(sys.stdout, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test daft concurrency levels\n",
    "\n",
    "Adapt [test 21 notebook (torch vs. daft-to-torch)](https://github.com/fr1ll/bedmap-dev/blob/clearer-atlas/nbs/daft-try/21_compare-daft-to-torch-data_clean.ipynb):\n",
    "- modify concurrency level for daft UDF used in embedding loop\n",
    "\n",
    "So far:\n",
    "- None: Same as without setting `with_concurrency_level` (makes sense as this is default)\n",
    "- 1 or 2: fails with error:\n",
    "`AttributeError: Can't get local object '_ensure_registered_super_ext_type.<locals>.DaftExtension'`\n",
    "    - This then triggers a memray error. Without memray, get same AttributeError."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set variables for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_DAFT: bool = True # else use torch dataset\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MODEL_NAME = \"vit_small_patch14_reg4_dinov2.lvd142m\"\n",
    "TEST_DATASET = \"kvriza8/microscopy_images\"\n",
    "NUM_TEST_IMAGES = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define way to download small test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_hf_images(dataset_name: str = \"kvriza8/microscopy_images\",\n",
    "                 dir: Path = None,\n",
    "                 max_images: int = 64,\n",
    "                 overwrite: bool = True,\n",
    "                 format: str = \"png\") -> None:\n",
    "\n",
    "    dataset = load_dataset(dataset_name, split=\"train\", streaming=True)\n",
    "    if overwrite:\n",
    "        shutil.rmtree(dir, ignore_errors=True)\n",
    "        dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    image_paths = []\n",
    "    for i, img_row in enumerate(tqdm(iter(dataset), total=max_images)):\n",
    "        if i >= max_images:\n",
    "            break\n",
    "        img = img_row[\"image\"]\n",
    "        image_paths += [(dir / f\"{i}.{format}\")]\n",
    "        img.save(image_paths[-1])\n",
    "\n",
    "    print(f\"Size of images on disk: {naturalsize(sum([p.stat().st_size for p in image_paths]))}\")\n",
    "\n",
    "    del dataset\n",
    "    gc.collect()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define timm-based embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Embedder:\n",
    "    \"\"\"instantiate pretrained timm model to generate embeddings\"\"\"\n",
    "    def __init__(self, model_name: str, device: torch.device = None):\n",
    "        self.model_name = model_name\n",
    "        # choose device and dtype\n",
    "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if self.device.type == \"cuda\":\n",
    "            self.dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "        else:\n",
    "            self.dtype = torch.float32\n",
    "\n",
    "        # Create and prepare the model\n",
    "        self.model = timm.create_model(self.model_name, pretrained=True, num_classes=0)\n",
    "        self.model.to(self.device, memory_format=torch.channels_last)\n",
    "        self.model.eval()\n",
    "        self.model = torch.compile(self.model, dynamic=True, mode=\"reduce-overhead\")\n",
    "\n",
    "        # must resolve config to drop unneeded fields\n",
    "        cfg = timm.data.resolve_data_config(self.model.pretrained_cfg)\n",
    "        self.transform = timm.data.create_transform(**cfg)\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def embed(self, batch_imgs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"set up input and embed it\"\"\"\n",
    "        batch_imgs = batch_imgs.to(self.device, non_blocking=True, memory_format=torch.channels_last)\n",
    "        if self.device.type == \"cuda\":\n",
    "            with torch.amp.autocast(\"cuda\", dtype=self.dtype):\n",
    "                return self.model(batch_imgs)\n",
    "        return self.model(batch_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define two types of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@daft.udf(return_dtype=daft.DataType.python())\n",
    "class TransformImagesDaft:\n",
    "    \"\"\"run timm embedder on an image column\"\"\"\n",
    "    def __init__(self, transform: callable):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, batch_images) -> list:\n",
    "        return [self.transform(Image.fromarray(im)) for im in batch_images.to_pylist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TorchImageIterAsDict(Dataset):\n",
    "    def __init__(self, filelist: list[Path], transform: callable):\n",
    "        self.filelist = filelist\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image = Image.open(self.filelist[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            return {\"image_transformed\": self.transform(image)}\n",
    "        # return as dict for easy comparison vs. daft\n",
    "        else:\n",
    "            return {\"image\": [image]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daft_to_torch_iter_from_glob(image_glob: str, transform: callable,\n",
    "                                 num_concurr: int | None):\n",
    "    \"\"\"generate a torch image dataset via daft from a glob\"\"\"\n",
    "\n",
    "    images_df = daft.from_glob_path(image_glob)\n",
    "    images_df = images_df.with_column(\"image\", daft.col(\"path\"\n",
    "                                    ).url.download().image.decode(\n",
    "                                        mode=\"RGB\", on_error=\"null\")\n",
    "                                    )\n",
    "    images_df = images_df.where(images_df[\"image\"].not_null())\n",
    "    TransformImForModel = TransformImagesDaft.with_init_args(transform=transform).with_concurrency(num_concurr)\n",
    "    images_df = images_df.with_column(\"image_transformed\", TransformImForModel(daft.col(\"image\"))\n",
    "                                    ).exclude(\"image\", \"num_rows\")\n",
    "    return images_df.to_torch_iter_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_iter_from_glob(image_glob: str, transform: callable):\n",
    "    \"\"\"generate a torch image dataset via daft from a glob\"\"\"\n",
    "\n",
    "    image_list = [Path(p) for p in glob(image_glob)]\n",
    "    return TorchImageIterAsDict(image_list, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Embedding computation pipeline including dataset instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(model_name: str, images_glob: str, batch_size: int = BATCH_SIZE,\n",
    "                       dataset_type: str = \"plain_torch\", daft_nconcurr: int | None = 1\n",
    "                       ) -> list[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Return a list of embeddings from a glob of images.\n",
    "    Uses a timm pretrained model to generate embeddings\n",
    "    \"\"\"\n",
    "    logger.info(\"Instantiating embedding model.\")\n",
    "    embedder = Embedder(model_name=model_name)\n",
    "\n",
    "    logger.info(f\"Creating dataset of type {dataset_type}.\")\n",
    "    if dataset_type == \"daft_to_torch\":\n",
    "        dataset = daft_to_torch_iter_from_glob(images_glob, embedder.transform, daft_nconcurr)\n",
    "    elif dataset_type == \"plain_torch\":\n",
    "        dataset = torch_iter_from_glob(images_glob, embedder.transform)\n",
    "    else:\n",
    "        raise ValueError(\"Dataset type must be `daft_to_torch` or `plain_torch`.\")\n",
    "\n",
    "    logger.info(\"Creating dataloader.\")\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    logger.info(\"Generating embeddings.\")\n",
    "    for i, batch_images in enumerate(tqdm(dataloader, unit_scale=BATCH_SIZE)):\n",
    "        emb = embedder.embed(batch_images[\"image_transformed\"]).cpu().numpy()\n",
    "        # if i == 0:\n",
    "        #     print(f\"Shape of embedding for one batch: {emb.shape}\")\n",
    "        embeddings.append(emb)\n",
    "    logger.info(\"Stacking embeddings.\")\n",
    "    embeddings = np.vstack(embeddings)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Do memory profiling with one type of dataset\n",
    "\n",
    "Results written near top of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-16 13:55:16.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mDownloading test images.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Memray WARNING: Correcting symbol for malloc from 0x420620 to 0x7ff290c71c60\n",
      "Memray WARNING: Correcting symbol for free from 0x420ab0 to 0x7ff290c72370\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 256/256 [00:14<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of images on disk: 19.5 MB\n",
      "\u001b[32m2025-03-16 13:55:34.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mStarting embedding pipeline.\u001b[0m\n",
      "\u001b[32m2025-03-16 13:55:34.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_embeddings\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mInstantiating embedding model.\u001b[0m\n",
      "\u001b[32m2025-03-16 13:55:37.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_embeddings\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mCreating dataset of type daft_to_torch.\u001b[0m\n",
      "\u001b[32m2025-03-16 13:55:37.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_embeddings\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mCreating dataloader.\u001b[0m\n",
      "\u001b[32m2025-03-16 13:55:37.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_embeddings\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mGenerating embeddings.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20839a4a3e8c400e888d26c7261b69ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üó°Ô∏è üêü Project: 00:00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5f207572fc4f58b374427facb5bc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üó°Ô∏è üêü Filter: 00:00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042849fb450a407aa8398cfccf173835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üó°Ô∏è üêü ActorPoolProject: 00:00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error when running pipeline node ActorPoolProject\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get local object '_ensure_registered_super_ext_type.<locals>.DaftExtension'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m imglob = tmp+\u001b[33m\"\u001b[39m\u001b[33m/*.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mStarting embedding pipeline.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m embeddings = \u001b[43mcompute_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mimages_glob\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimglob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mdaft_nconcurr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONCURRENCY_LEVEL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mDone with embedding pipeline.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mcompute_embeddings\u001b[39m\u001b[34m(model_name, images_glob, batch_size, dataset_type, daft_nconcurr)\u001b[39m\n\u001b[32m     22\u001b[39m embeddings = []\n\u001b[32m     24\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mGenerating embeddings.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_images\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43memb\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43membedder\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_images\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage_transformed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# if i == 0:\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     print(f\"Shape of embedding for one batch: {emb.shape}\")\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:33\u001b[39m, in \u001b[36m_IterableDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m         data.append(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     35\u001b[39m         \u001b[38;5;28mself\u001b[39m.ended = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/dataframe/dataframe.py:369\u001b[39m, in \u001b[36mDataFrame.iter_rows\u001b[39m\u001b[34m(self, results_buffer_size, column_format)\u001b[39m\n\u001b[32m    364\u001b[39m partitions_iter = context.get_or_create_runner().run_iter_tables(\n\u001b[32m    365\u001b[39m     \u001b[38;5;28mself\u001b[39m._builder, results_buffer_size=results_buffer_size\n\u001b[32m    366\u001b[39m )\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# Iterate through partitions.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpartitions_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumn_format\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpython\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpython_iter_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/runners/native_runner.py:93\u001b[39m, in \u001b[36mNativeRunner.run_iter_tables\u001b[39m\u001b[34m(self, builder, results_buffer_size)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_iter_tables\u001b[39m(\n\u001b[32m     91\u001b[39m     \u001b[38;5;28mself\u001b[39m, builder: LogicalPlanBuilder, results_buffer_size: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     92\u001b[39m ) -> Iterator[MicroPartition]:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_buffer_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults_buffer_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/runners/native_runner.py:88\u001b[39m, in \u001b[36mNativeRunner.run_iter\u001b[39m\u001b[34m(self, builder, results_buffer_size)\u001b[39m\n\u001b[32m     81\u001b[39m executor = NativeExecutor()\n\u001b[32m     82\u001b[39m results_gen = executor.run(\n\u001b[32m     83\u001b[39m     builder,\n\u001b[32m     84\u001b[39m     {k: v.values() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._part_set_cache.get_all_partition_sets().items()},\n\u001b[32m     85\u001b[39m     daft_execution_config,\n\u001b[32m     86\u001b[39m     results_buffer_size,\n\u001b[32m     87\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m results_gen\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/execution/native_executor.py:39\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdaft\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunners\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartitioning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LocalMaterializedResult\n\u001b[32m     34\u001b[39m psets_mp = {\n\u001b[32m     35\u001b[39m     part_id: [part.micropartition()._micropartition \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m parts] \u001b[38;5;28;01mfor\u001b[39;00m part_id, parts \u001b[38;5;129;01min\u001b[39;00m psets.items()\n\u001b[32m     36\u001b[39m }\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mLocalMaterializedResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMicroPartition\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_from_pymicropartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_builder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsets_mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaft_execution_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_buffer_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/daft/execution/actor_pool_udf.py:45\u001b[39m, in \u001b[36mActorHandle.eval_input\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: PyMicroPartition) -> PyMicroPartition:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_conn\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMicroPartition\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_from_pymicropartition\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     output: MicroPartition = \u001b[38;5;28mself\u001b[39m.handle_conn.recv()\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output._micropartition\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:206\u001b[39m, in \u001b[36m_ConnectionBase.send\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    205\u001b[39m \u001b[38;5;28mself\u001b[39m._check_writable()\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[38;5;28mself\u001b[39m._send_bytes(\u001b[43m_ForkingPickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/reduction.py:51\u001b[39m, in \u001b[36mForkingPickler.dumps\u001b[39m\u001b[34m(cls, obj, protocol)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdumps\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     50\u001b[39m     buf = io.BytesIO()\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m buf.getbuffer()\n",
      "\u001b[31mAttributeError\u001b[39m: Can't get local object '_ensure_registered_super_ext_type.<locals>.DaftExtension'"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdf8bb6a262433383dc9deb80726db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Memray ERROR: Invalid record subtype\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ö† <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> No debug information was found for the Python interpreter </span> ‚ö†\n",
       "\n",
       "Without debug information reports showing native traces <span style=\"font-weight: bold\">may not include file names and line numbers</span>. Please use an \n",
       "interpreter built with debug symbols for best results. Check <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://bloomberg.github.io/memray/native_mode.html</span> \n",
       "for more information regarding how memray resolves symbols.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ö† \u001b[1;33m No debug information was found for the Python interpreter \u001b[0m ‚ö†\n",
       "\n",
       "Without debug information reports showing native traces \u001b[1mmay not include file names and line numbers\u001b[0m. Please use an \n",
       "interpreter built with debug symbols for best results. Check \u001b[4;94mhttps://bloomberg.github.io/memray/native_mode.html\u001b[0m \n",
       "for more information regarding how memray resolves symbols.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de0578469e04c318df6dbeb8c51376b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmemray_flamegraph\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--native --follow-fork --temporal\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mUSE_DAFT = True\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mCONCURRENCY_LEVEL = 2\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mds_type = \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdaft_to_torch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m if USE_DAFT else \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mplain_torch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mwith TemporaryDirectory() as tmp:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    logger.info(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDownloading test images.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    dl_hf_images(dir=Path(tmp), max_images=NUM_TEST_IMAGES)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    imglob = tmp+\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/*.png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    logger.info(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mStarting embedding pipeline.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    embeddings = compute_embeddings(model_name=MODEL_NAME,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                                    images_glob = imglob,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                                    batch_size=BATCH_SIZE,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                                    dataset_type=ds_type,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                                    daft_nconcurr=CONCURRENCY_LEVEL)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    logger.info(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDone with embedding pipeline.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2542\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2540\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2541\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2542\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2544\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2545\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2546\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2547\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/memray/_ipython/flamegraph.py:188\u001b[39m, in \u001b[36mFlamegraphMagics.memray_flamegraph\u001b[39m\u001b[34m(self, line, cell)\u001b[39m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    185\u001b[39m         recs, hwms = reader.get_temporal_high_water_mark_allocation_records(\n\u001b[32m    186\u001b[39m             merge_threads=merge_threads\n\u001b[32m    187\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m         reporter = \u001b[43mFlameGraphReporter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_temporal_snapshot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrecs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmemory_records\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_memory_snapshots\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnative_traces\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_native_traces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhigh_water_mark_by_snapshot\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhwms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[43minverted\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43minverted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m options.show_memory_leaks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/memray/reporters/flamegraph.py:377\u001b[39m, in \u001b[36mFlameGraphReporter.from_temporal_snapshot\u001b[39m\u001b[34m(cls, allocations, memory_records, native_traces, high_water_mark_by_snapshot, inverted)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_temporal_snapshot\u001b[39m(\n\u001b[32m    369\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    375\u001b[39m     inverted: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    376\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mFlameGraphReporter\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_from_any_snapshot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallocations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_records\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_records\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnative_traces\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnative_traces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemporal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43minverted\u001b[49m\u001b[43m=\u001b[49m\u001b[43minverted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    384\u001b[39m     ret.data[\u001b[33m\"\u001b[39m\u001b[33mhigh_water_mark_by_snapshot\u001b[39m\u001b[33m\"\u001b[39m] = high_water_mark_by_snapshot\n\u001b[32m    385\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/bedmap-dev/.venv/lib/python3.12/site-packages/memray/reporters/flamegraph.py:288\u001b[39m, in \u001b[36mFlameGraphReporter._from_any_snapshot\u001b[39m\u001b[34m(cls, allocations, memory_records, native_traces, temporal, inverted)\u001b[39m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(record, TemporalAllocationRecord)\n\u001b[32m    280\u001b[39m     record_data = {\n\u001b[32m    281\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthread_name\u001b[39m\u001b[33m\"\u001b[39m: format_thread_name(record),\n\u001b[32m    282\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mintervals\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    283\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m: record.size,\n\u001b[32m    284\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mn_allocations\u001b[39m\u001b[33m\"\u001b[39m: record.n_allocations,\n\u001b[32m    285\u001b[39m     }\n\u001b[32m    287\u001b[39m stack = (\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28mtuple\u001b[39m(\u001b[43mrecord\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhybrid_stack_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m native_traces\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m record.stack_trace()\n\u001b[32m    291\u001b[39m )\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inverted:\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# normal flamegraph\u001b[39;00m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28mcls\u001b[39m.generate_frames(\n\u001b[32m    296\u001b[39m         stack_it=\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(stack)),\n\u001b[32m    297\u001b[39m         frames=frames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    301\u001b[39m         interval_list=interval_list,\n\u001b[32m    302\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%%memray_flamegraph --native --follow-fork --temporal\n",
    "\n",
    "USE_DAFT = True\n",
    "CONCURRENCY_LEVEL = 1\n",
    "ds_type = \"daft_to_torch\" if USE_DAFT else \"plain_torch\"\n",
    "\n",
    "with TemporaryDirectory() as tmp:\n",
    "    logger.info(\"Downloading test images.\")\n",
    "    dl_hf_images(dir=Path(tmp), max_images=NUM_TEST_IMAGES)\n",
    "    imglob = tmp+\"/*.png\"\n",
    "    logger.info(\"Starting embedding pipeline.\")\n",
    "    embeddings = compute_embeddings(model_name=MODEL_NAME,\n",
    "                                    images_glob = imglob,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    dataset_type=ds_type,\n",
    "                                    daft_nconcurr=CONCURRENCY_LEVEL)\n",
    "    logger.info(\"Done with embedding pipeline.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
